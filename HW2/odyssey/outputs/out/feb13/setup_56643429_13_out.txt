[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW2/PTB.hdf5	Classifier:	lr	Alpha:	0	Eta:	10	Lambda:	1	Minibatch size:	64	Num Epochs:	20	
nclasses:	45	nsparsefeatures:	101214	ndensefeatures:	3	
Imported all data	
Began logistic regression	
Got parameters	101214	3	45	
Set up ParallelTable	
Set up model	
Set up criterion	
Got params and grads	
Epoch 1	
 2027
 2602
 2190
 2268
 5821
 1998
 1432
 2111
 1398
 4583
 3808
 1580
 1375
 1317
  944
 1451
 4216
 1373
 2156
 4613
 5436
  575
 6403
 3090
 1516
 4476
 6636
 1546
 4220
 1768
 3204
 1142
 4518
 2455
 3218
 2713
 8980
 1951
 3885
 2754
 2217
 1312
 3807
 1120
 3603
[torch.DoubleTensor of size 45]

Validation accuracy:	0.024194282592862	
Grad norm	0	
    Loss 2276644.3277005	
    Loss 1977534.0247475	
    Loss 1717877.9879835	
    Loss 1492360.4175477	
    Loss 1296491.3608798	
    Loss 1126381.4341617	
    Loss 978593.91249614	
    Loss 850234.05544204	
    Loss 738715.48050283	
    Loss 641863.55724371	
    Loss 557726.85561688	
    Loss 484636.62964575	
    Loss 421140.23571556	
    Loss 365982.67380021	
    Loss 318071.23835848	
    Loss 276426.94347202	
    Loss 240268.99200049	
    Loss 208860.90947802	
    Loss 181562.47176835	
    Loss 157852.45609082	
    Loss 137248.8704338	
    Loss 119355.99430292	
    Loss 103806.19039815	
    Loss 90301.62671395	
    Loss 78559.21767564	
    Loss 68365.757076826	
    Loss 59509.145871768	
    Loss 51812.528026473	
    Loss 45127.310829786	
    Loss 39317.803700057	
    Loss 34280.000846411	
    Loss 29887.298199361	
    Loss 26083.275431294	
    Loss 22776.919512311	
    Loss 19901.795223875	
    Loss 17409.291831952	
    Loss 15238.323985103	
    Loss 13351.554736401	
    Loss 11713.699381064	
    Loss 10285.864815166	
    Loss 9059.005730791	
    Loss 7979.4623428103	
    Loss 7040.1554470326	
    Loss 6227.5002478845	
    Loss 5530.8784832052	
    Loss 4916.6847923092	
    Loss 4385.1535575962	
    Loss 3921.7517003403	
    Loss 3514.392793904	
    Loss 3164.4365642061	
    Loss 2857.3891530296	
    Loss 2601.7779637798	
    Loss 2370.0033118016	
    Loss 2174.1482721525	
    Loss 2004.0575194679	
    Loss 1854.1466007005	
    Loss 1721.016402408	
    Loss 1610.4591907895	
    Loss 1516.6847072427	
    Loss 1432.8658854677	
    Loss 1349.063253241	
    Loss 1285.4257728924	
    Loss 1234.0810680616	
    Loss 1176.5246579316	
    Loss 1137.4284346595	
    Loss 1102.0038992208	
    Loss 1073.9908666156	
    Loss 1044.6132193262	
    Loss 1015.2205094577	
    Loss 1005.3796635976	
    Loss 985.64519797125	
    Loss 965.43795905375	
    Loss 949.39414362327	
    Loss 938.77859270893	
    Loss 927.295067197	
    Loss 914.02560128967	
    Loss 904.10566821358	
    Loss 891.73657749896	
    Loss 890.3707599885	
    Loss 894.77912729844	
    Loss 885.91913562619	
    Loss 885.19219531973	
    Loss 873.26239015808	
    Loss 874.36230289316	
    Loss 880.7865482215	
    Loss 868.99472859735	
    Loss 858.2784672944	
    Loss 863.73917304908	
    Loss 861.46139629716	
    Loss 864.45378523914	
    Loss 865.53750994678	
    Loss 863.67026576635	
    Loss 863.41435250321	
    Loss 857.61432130036	
    Loss 851.59550478656	
    Loss 845.21593188083	
    Loss 845.53931831934	
    Loss 834.31637467011	
    Loss 839.20603084898	
    Loss 841.55047951744	
    Loss 850.33815158495	
    Loss 854.43392117881	
    Loss 855.57202195455	
    Loss 856.49501424866	
    Loss 863.24574285465	
    Loss 866.92135881102	
    Loss 857.65323734522	
    Loss 851.16537189364	
    Loss 858.09118444152	
    Loss 847.56874552073	
    Loss 851.72409618028	
    Loss 853.64510860416	
    Loss 848.82833017307	
    Loss 851.24791701609	
    Loss 852.93913827456	
    Loss 863.83273967664	
    Loss 855.91778895383	
    Loss 861.37470855516	
    Loss 860.02763478136	
    Loss 855.32743430747	
    Loss 852.59640066475	
    Loss 854.62351318046	
    Loss 851.56294392935	
    Loss 851.08059049893	
    Loss 850.71181198278	
    Loss 853.64307918013	
    Loss 852.95342444979	
    Loss 858.16941215052	
    Loss 861.08930608405	
    Loss 860.13966824255	
    Loss 859.59012309995	
    Loss 853.70395524454	
    Loss 844.58947207241	
    Loss 839.42381237279	
    Loss 841.86112493779	
    Loss 845.74908759434	
    Loss 849.2253430602	
    Loss 852.05187855287	
    Loss 861.01237542195	
    Loss 861.47079504302	
    Loss 856.19847037296	
    Loss 855.41131978877	
    Loss 859.99665225869	
Epoch 2	
  5509
  2063
    70
     0
 41843
     0
     0
 15920
 61291
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4777478460023	
    Loss 848.96881861302	
    Loss 856.30774503359	
    Loss 862.8885095439	
    Loss 859.19136585668	
    Loss 859.34657391076	
    Loss 859.85758671562	
    Loss 858.06829628596	
    Loss 858.40250901014	
    Loss 866.73114433885	
    Loss 866.4757741403	
    Loss 866.58366192155	
    Loss 864.21355762148	
    Loss 854.07545917535	
    Loss 850.33491644619	
    Loss 852.36592471992	
    Loss 844.23277697895	
    Loss 853.62405307907	
    Loss 860.78335467285	
    Loss 856.60035291802	
    Loss 853.24665798646	
    Loss 857.76408072837	
    Loss 859.77861380524	
    Loss 864.06219933612	
    Loss 865.85886008988	
    Loss 859.65786355289	
    Loss 860.92705108869	
    Loss 854.44955828024	
    Loss 852.46012575776	
    Loss 853.22446118916	
    Loss 849.34670410721	
    Loss 857.69423288934	
    Loss 850.25899928152	
    Loss 856.34385015312	
    Loss 857.9414841644	
    Loss 857.0133444378	
    Loss 861.64339339112	
    Loss 859.69333947489	
    Loss 859.31264669706	
    Loss 859.7928695893	
    Loss 856.50457845691	
    Loss 866.37226868959	
    Loss 861.7053370062	
    Loss 855.56611186133	
    Loss 853.83410385881	
    Loss 862.04154198505	
    Loss 860.03948150814	
    Loss 861.27754796275	
    Loss 860.4340923068	
    Loss 854.63781701672	
    Loss 853.01044547238	
    Loss 849.28652331866	
    Loss 857.10373843223	
    Loss 853.49072323987	
    Loss 856.50841621026	
    Loss 859.01593113392	
    Loss 859.42391258059	
    Loss 856.86007785919	
    Loss 859.75762793228	
    Loss 864.30249087542	
    Loss 865.89716337358	
    Loss 856.43398845499	
    Loss 857.31935949372	
    Loss 862.11705987732	
    Loss 853.20639766088	
    Loss 856.61600071968	
    Loss 857.9423687834	
    Loss 861.88978468497	
    Loss 860.30568322554	
    Loss 855.02179706351	
    Loss 866.04105655381	
    Loss 864.61749487601	
    Loss 860.28301897863	
    Loss 857.94106299613	
    Loss 859.21242023652	
    Loss 858.10735935933	
    Loss 853.93855231093	
    Loss 851.88778745988	
    Loss 846.32044229609	
    Loss 850.88836018758	
    Loss 860.52040386752	
    Loss 856.17824698115	
    Loss 859.378796235	
    Loss 850.82010531037	
    Loss 854.86383593959	
    Loss 863.83983576205	
    Loss 854.27916482342	
    Loss 845.47868429732	
    Loss 852.60456009802	
    Loss 851.79095936594	
    Loss 856.06522519498	
    Loss 858.26712200111	
    Loss 857.37060805107	
    Loss 857.92635265112	
    Loss 852.87138798293	
    Loss 847.57875847291	
    Loss 841.66377271569	
    Loss 842.44379764445	
    Loss 831.6186324591	
    Loss 836.8671356078	
    Loss 839.50482555368	
    Loss 848.5642208687	
    Loss 852.90999717409	
    Loss 854.26381995297	
    Loss 855.36739774197	
    Loss 862.27776568062	
    Loss 866.11208640953	
    Loss 856.93638855123	
    Loss 850.57302833688	
    Loss 857.56285258081	
    Loss 847.13405605296	
    Loss 851.34196872765	
    Loss 853.30746901143	
    Loss 848.53762309	
    Loss 850.99584150772	
    Loss 852.72187915427	
    Loss 863.64330831096	
    Loss 855.7565520681	
    Loss 861.23189955372	
    Loss 859.90778622294	
    Loss 855.22729580105	
    Loss 852.51316214524	
    Loss 854.55587866679	
    Loss 851.50986832606	
    Loss 851.03764327653	
    Loss 850.67707166903	
    Loss 853.6148753446	
    Loss 852.93248461272	
    Loss 858.1584586277	
    Loss 861.0814273063	
    Loss 860.14595014742	
    Loss 859.58839543119	
    Loss 853.70503823551	
    Loss 844.59282398799	
    Loss 839.43038615933	
    Loss 841.87006491674	
    Loss 845.76011792211	
    Loss 849.23694189	
    Loss 852.06629425666	
    Loss 861.02821762961	
    Loss 861.48847470638	
    Loss 856.21669657845	
    Loss 855.42999007752	
    Loss 860.01571158205	
Epoch 3	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.471293035083	
    Loss 848.98806057957	
    Loss 856.32451374344	
    Loss 862.90376114297	
    Loss 859.20495392262	
    Loss 859.35822746195	
    Loss 859.86730979181	
    Loss 858.07687917062	
    Loss 858.40976965943	
    Loss 866.7372898914	
    Loss 866.48115519508	
    Loss 866.58809530799	
    Loss 864.21717181395	
    Loss 854.07830349241	
    Loss 850.33746471904	
    Loss 852.36833584001	
    Loss 844.23490304776	
    Loss 853.62598853578	
    Loss 860.78504759082	
    Loss 856.60180530518	
    Loss 853.24787348796	
    Loss 857.76531624675	
    Loss 859.77955128352	
    Loss 864.0631437423	
    Loss 865.8596518422	
    Loss 859.65859296991	
    Loss 860.92769263333	
    Loss 854.45012184445	
    Loss 852.46057561156	
    Loss 853.22498324874	
    Loss 849.34714689778	
    Loss 857.69457026233	
    Loss 850.25929588475	
    Loss 856.34414431463	
    Loss 857.94168668242	
    Loss 857.01346923169	
    Loss 861.64346709534	
    Loss 859.69338851659	
    Loss 859.31267363542	
    Loss 859.79288672126	
    Loss 856.50461855411	
    Loss 866.37231699687	
    Loss 861.70538325999	
    Loss 855.5661242339	
    Loss 853.83409863019	
    Loss 862.04154726197	
    Loss 860.03947342305	
    Loss 861.27754148587	
    Loss 860.43408294521	
    Loss 854.63781642678	
    Loss 853.01041095077	
    Loss 849.28650141362	
    Loss 857.10370511429	
    Loss 853.49068065705	
    Loss 856.50840029237	
    Loss 859.01591442501	
    Loss 859.42391174683	
    Loss 856.86008498482	
    Loss 859.75764046749	
    Loss 864.30250397244	
    Loss 865.89716782688	
    Loss 856.43400037571	
    Loss 857.31937032696	
    Loss 862.11706936014	
    Loss 853.20640087838	
    Loss 856.61600618953	
    Loss 857.94237328733	
    Loss 861.88978643357	
    Loss 860.30568440757	
    Loss 855.02179688475	
    Loss 866.04105384069	
    Loss 864.61749307619	
    Loss 860.28301897328	
    Loss 857.94106216669	
    Loss 859.21242333808	
    Loss 858.10736141837	
    Loss 853.93855605999	
    Loss 851.88779060962	
    Loss 846.32044216672	
    Loss 850.88835698264	
    Loss 860.52040361333	
    Loss 856.17824897085	
    Loss 859.37879739201	
    Loss 850.82010643006	
    Loss 854.86383515923	
    Loss 863.83983556369	
    Loss 854.27916413982	
    Loss 845.47868074945	
    Loss 852.60455729356	
    Loss 851.79095814859	
    Loss 856.06522505159	
    Loss 858.26712195432	
    Loss 857.37061044543	
    Loss 857.92635312503	
    Loss 852.8713903717	
    Loss 847.57880927853	
    Loss 841.66378141004	
    Loss 842.44380247962	
    Loss 831.61863310522	
    Loss 836.86713975659	
    Loss 839.50482664306	
    Loss 848.56422198881	
    Loss 852.90999741891	
    Loss 854.26382212514	
    Loss 855.3674003251	
    Loss 862.27776879295	
    Loss 866.11208881956	
    Loss 856.93639320447	
    Loss 850.57302303247	
    Loss 857.56285413827	
    Loss 847.1340520307	
    Loss 851.34196627399	
    Loss 853.30746873434	
    Loss 848.53762165936	
    Loss 850.99584158179	
    Loss 852.72188017878	
    Loss 863.64331031268	
    Loss 855.75655553604	
    Loss 861.23189999793	
    Loss 859.90778797338	
    Loss 855.2272981687	
    Loss 852.51316281086	
    Loss 854.55588053864	
    Loss 851.50986910066	
    Loss 851.03764523526	
    Loss 850.67707413766	
    Loss 853.61487788428	
    Loss 852.93248683498	
    Loss 858.15846075241	
    Loss 861.08142932752	
    Loss 860.145942033	
    Loss 859.58839735174	
    Loss 853.70503970162	
    Loss 844.59282546533	
    Loss 839.43038794658	
    Loss 841.87006633108	
    Loss 845.7601192122	
    Loss 849.2369432253	
    Loss 852.06629546275	
    Loss 861.02821894557	
    Loss 861.48847592343	
    Loss 856.2166975134	
    Loss 855.42999098744	
    Loss 860.0157123407	
Epoch 4	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4712929677483	
    Loss 848.98806122814	
    Loss 856.32451428994	
    Loss 862.90376176891	
    Loss 859.20495444856	
    Loss 859.35822789842	
    Loss 859.8673102124	
    Loss 858.07687951877	
    Loss 858.40976996839	
    Loss 866.73729011263	
    Loss 866.48115530601	
    Loss 866.58809537184	
    Loss 864.21717180843	
    Loss 854.07830346657	
    Loss 850.33746466924	
    Loss 852.36833578908	
    Loss 844.2349030572	
    Loss 853.62598854546	
    Loss 860.78504762455	
    Loss 856.60180531223	
    Loss 853.24787351946	
    Loss 857.76531627409	
    Loss 859.77955131035	
    Loss 864.06314378769	
    Loss 865.85965186123	
    Loss 859.65859299573	
    Loss 860.9276926425	
    Loss 854.45012186042	
    Loss 852.46057563284	
    Loss 853.22498325972	
    Loss 849.34714689731	
    Loss 857.69457027844	
    Loss 850.25929589908	
    Loss 856.34414432422	
    Loss 857.94168668145	
    Loss 857.01346923316	
    Loss 861.64346709968	
    Loss 859.69338851606	
    Loss 859.3126736233	
    Loss 859.79288671232	
    Loss 856.50461854183	
    Loss 866.37231698002	
    Loss 861.70538324275	
    Loss 855.56612422625	
    Loss 853.8340986226	
    Loss 862.04154725089	
    Loss 860.03947342479	
    Loss 861.27754149059	
    Loss 860.43408294873	
    Loss 854.63781642928	
    Loss 853.01041095307	
    Loss 849.28650141686	
    Loss 857.10370511809	
    Loss 853.49068065895	
    Loss 856.50840029292	
    Loss 859.01591442357	
    Loss 859.42391174379	
    Loss 856.86008498016	
    Loss 859.75764046473	
    Loss 864.3025039696	
    Loss 865.89716782409	
    Loss 856.43400037186	
    Loss 857.31937032351	
    Loss 862.11706935562	
    Loss 853.20640087389	
    Loss 856.61600618673	
    Loss 857.94237328513	
    Loss 861.88978643125	
    Loss 860.30568440534	
    Loss 855.02179688346	
    Loss 866.04105383853	
    Loss 864.61749307525	
    Loss 860.28301897235	
    Loss 857.94106216574	
    Loss 859.2124233367	
    Loss 858.1073614176	
    Loss 853.93855605935	
    Loss 851.8877906089	
    Loss 846.32044216564	
    Loss 850.88835698167	
    Loss 860.52040361319	
    Loss 856.17824897075	
    Loss 859.37879739188	
    Loss 850.82010643028	
    Loss 854.86383515963	
    Loss 863.83983556392	
    Loss 854.2791641402	
    Loss 845.47868074922	
    Loss 852.60455729342	
    Loss 851.79095814857	
    Loss 856.06522505154	
    Loss 858.26712195428	
    Loss 857.37061044536	
    Loss 857.92635312488	
    Loss 852.87139037162	
    Loss 847.57880925751	
    Loss 841.6637814069	
    Loss 842.44380247822	
    Loss 831.6186331053	
    Loss 836.86713975527	
    Loss 839.50482664265	
    Loss 848.56422198828	
    Loss 852.90999741909	
    Loss 854.26382212477	
    Loss 855.36740032462	
    Loss 862.2777687923	
    Loss 866.11208881832	
    Loss 856.93639320308	
    Loss 850.57302303599	
    Loss 857.56285413851	
    Loss 847.13405203348	
    Loss 851.34196627591	
    Loss 853.3074687352	
    Loss 848.53762166058	
    Loss 850.99584158242	
    Loss 852.72188017891	
    Loss 863.64331031243	
    Loss 855.75655553499	
    Loss 861.23189999829	
    Loss 859.90778797314	
    Loss 855.22729816808	
    Loss 852.51316281113	
    Loss 854.55588053834	
    Loss 851.50986910083	
    Loss 851.03764523495	
    Loss 850.67707413702	
    Loss 853.61487788361	
    Loss 852.93248683446	
    Loss 858.15846075192	
    Loss 861.08142932701	
    Loss 860.14594203725	
    Loss 859.58839735129	
    Loss 853.70503970132	
    Loss 844.59282546502	
    Loss 839.43038794616	
    Loss 841.8700663308	
    Loss 845.760119212	
    Loss 849.23694322506	
    Loss 852.06629546259	
    Loss 861.02821894539	
    Loss 861.48847592329	
    Loss 856.21669751336	
    Loss 855.42999098742	
    Loss 860.01571234077	
Epoch 5	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4712929677729	
    Loss 848.98806122826	
    Loss 856.32451429007	
    Loss 862.90376176895	
    Loss 859.2049544486	
    Loss 859.35822789847	
    Loss 859.8673102124	
    Loss 858.07687951878	
    Loss 858.40976996838	
    Loss 866.73729011266	
    Loss 866.48115530607	
    Loss 866.58809537192	
    Loss 864.21717180852	
    Loss 854.07830346664	
    Loss 850.33746466934	
    Loss 852.36833578917	
    Loss 844.23490305724	
    Loss 853.6259885455	
    Loss 860.78504762456	
    Loss 856.60180531226	
    Loss 853.24787351947	
    Loss 857.7653162741	
    Loss 859.77955131036	
    Loss 864.06314378769	
    Loss 865.85965186123	
    Loss 859.65859299573	
    Loss 860.9276926425	
    Loss 854.45012186042	
    Loss 852.46057563284	
    Loss 853.22498325972	
    Loss 849.34714689733	
    Loss 857.69457027843	
    Loss 850.25929589907	
    Loss 856.34414432422	
    Loss 857.94168668146	
    Loss 857.01346923316	
    Loss 861.64346709968	
    Loss 859.69338851606	
    Loss 859.31267362331	
    Loss 859.79288671233	
    Loss 856.50461854184	
    Loss 866.37231698003	
    Loss 861.70538324276	
    Loss 855.56612422625	
    Loss 853.8340986226	
    Loss 862.04154725089	
    Loss 860.03947342479	
    Loss 861.27754149058	
    Loss 860.43408294873	
    Loss 854.63781642928	
    Loss 853.01041095307	
    Loss 849.28650141686	
    Loss 857.10370511809	
    Loss 853.49068065895	
    Loss 856.50840029293	
    Loss 859.01591442357	
    Loss 859.4239117438	
    Loss 856.86008498016	
    Loss 859.75764046473	
    Loss 864.3025039696	
    Loss 865.89716782409	
    Loss 856.43400037185	
    Loss 857.31937032352	
    Loss 862.11706935562	
    Loss 853.20640087389	
    Loss 856.61600618673	
    Loss 857.94237328512	
    Loss 861.88978643125	
    Loss 860.30568440534	
    Loss 855.02179688346	
    Loss 866.04105383854	
    Loss 864.61749307525	
    Loss 860.28301897235	
    Loss 857.94106216574	
    Loss 859.2124233367	
    Loss 858.1073614176	
    Loss 853.93855605935	
    Loss 851.8877906089	
    Loss 846.32044216564	
    Loss 850.88835698167	
    Loss 860.52040361319	
    Loss 856.17824897075	
    Loss 859.37879739188	
    Loss 850.82010643028	
    Loss 854.86383515963	
    Loss 863.83983556392	
    Loss 854.2791641402	
    Loss 845.47868074922	
    Loss 852.60455729342	
    Loss 851.79095814857	
    Loss 856.06522505154	
    Loss 858.26712195428	
    Loss 857.37061044536	
    Loss 857.92635312488	
    Loss 852.87139037162	
    Loss 847.57880925752	
    Loss 841.66378140691	
    Loss 842.44380247822	
    Loss 831.6186331053	
    Loss 836.86713975527	
    Loss 839.50482664265	
    Loss 848.56422198828	
    Loss 852.90999741909	
    Loss 854.26382212477	
    Loss 855.36740032462	
    Loss 862.2777687923	
    Loss 866.11208881832	
    Loss 856.93639320308	
    Loss 850.57302303598	
    Loss 857.56285413851	
    Loss 847.13405203348	
    Loss 851.34196627591	
    Loss 853.3074687352	
    Loss 848.53762166057	
    Loss 850.99584158242	
    Loss 852.72188017891	
    Loss 863.64331031243	
    Loss 855.75655553499	
    Loss 861.23189999829	
    Loss 859.90778797315	
    Loss 855.22729816808	
    Loss 852.51316281113	
    Loss 854.55588053834	
    Loss 851.50986910083	
    Loss 851.03764523495	
    Loss 850.67707413702	
    Loss 853.61487788361	
    Loss 852.93248683446	
    Loss 858.15846075192	
    Loss 861.08142932701	
    Loss 860.14594203724	
    Loss 859.58839735129	
    Loss 853.70503970132	
    Loss 844.59282546502	
    Loss 839.43038794616	
    Loss 841.8700663308	
    Loss 845.760119212	
    Loss 849.23694322506	
    Loss 852.06629546259	
    Loss 861.02821894539	
    Loss 861.48847592329	
    Loss 856.21669751336	
    Loss 855.42999098742	
    Loss 860.01571234077	
Epoch 6	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4712929677729	
    Loss 848.98806122826	
    Loss 856.32451429007	
    Loss 862.90376176895	
    Loss 859.2049544486	
    Loss 859.35822789847	
    Loss 859.8673102124	
    Loss 858.07687951878	
    Loss 858.40976996838	
    Loss 866.73729011266	
    Loss 866.48115530607	
    Loss 866.58809537192	
    Loss 864.21717180852	
    Loss 854.07830346664	
    Loss 850.33746466934	
    Loss 852.36833578917	
    Loss 844.23490305724	
    Loss 853.6259885455	
    Loss 860.78504762456	
    Loss 856.60180531226	
    Loss 853.24787351947	
    Loss 857.7653162741	
    Loss 859.77955131036	
    Loss 864.06314378769	
    Loss 865.85965186123	
    Loss 859.65859299573	
    Loss 860.9276926425	
    Loss 854.45012186042	
    Loss 852.46057563284	
    Loss 853.22498325972	
    Loss 849.34714689733	
    Loss 857.69457027843	
    Loss 850.25929589907	
    Loss 856.34414432422	
    Loss 857.94168668146	
    Loss 857.01346923316	
    Loss 861.64346709968	
    Loss 859.69338851606	
    Loss 859.31267362331	
    Loss 859.79288671233	
    Loss 856.50461854184	
    Loss 866.37231698003	
    Loss 861.70538324276	
    Loss 855.56612422625	
    Loss 853.8340986226	
    Loss 862.04154725089	
    Loss 860.03947342479	
    Loss 861.27754149059	
    Loss 860.43408294873	
    Loss 854.63781642928	
    Loss 853.01041095307	
    Loss 849.28650141686	
    Loss 857.10370511809	
    Loss 853.49068065895	
    Loss 856.50840029293	
    Loss 859.01591442357	
    Loss 859.4239117438	
    Loss 856.86008498016	
    Loss 859.75764046473	
    Loss 864.3025039696	
    Loss 865.89716782409	
    Loss 856.43400037185	
    Loss 857.31937032352	
    Loss 862.11706935562	
    Loss 853.20640087389	
    Loss 856.61600618673	
    Loss 857.94237328512	
    Loss 861.88978643125	
    Loss 860.30568440534	
    Loss 855.02179688346	
    Loss 866.04105383854	
    Loss 864.61749307525	
    Loss 860.28301897235	
    Loss 857.94106216574	
    Loss 859.2124233367	
    Loss 858.1073614176	
    Loss 853.93855605935	
    Loss 851.8877906089	
    Loss 846.32044216564	
    Loss 850.88835698167	
    Loss 860.52040361319	
    Loss 856.17824897075	
    Loss 859.37879739188	
    Loss 850.82010643028	
    Loss 854.86383515963	
    Loss 863.83983556392	
    Loss 854.27916414019	
    Loss 845.47868074922	
    Loss 852.60455729342	
    Loss 851.79095814857	
    Loss 856.06522505154	
    Loss 858.26712195428	
    Loss 857.37061044536	
    Loss 857.92635312488	
    Loss 852.87139037162	
    Loss 847.57880925752	
    Loss 841.66378140691	
    Loss 842.44380247822	
    Loss 831.6186331053	
    Loss 836.86713975527	
    Loss 839.50482664265	
    Loss 848.56422198828	
    Loss 852.90999741909	
    Loss 854.26382212477	
    Loss 855.36740032462	
    Loss 862.2777687923	
    Loss 866.11208881832	
    Loss 856.93639320308	
    Loss 850.57302303598	
    Loss 857.56285413851	
    Loss 847.13405203348	
    Loss 851.34196627591	
    Loss 853.3074687352	
    Loss 848.53762166058	
    Loss 850.99584158242	
    Loss 852.72188017891	
    Loss 863.64331031243	
    Loss 855.75655553499	
    Loss 861.23189999829	
    Loss 859.90778797315	
    Loss 855.22729816808	
    Loss 852.51316281113	
    Loss 854.55588053834	
    Loss 851.50986910082	
    Loss 851.03764523495	
    Loss 850.67707413702	
    Loss 853.61487788361	
    Loss 852.93248683446	
    Loss 858.15846075192	
    Loss 861.08142932701	
    Loss 860.14594203724	
    Loss 859.58839735129	
    Loss 853.70503970132	
    Loss 844.59282546502	
    Loss 839.43038794616	
    Loss 841.8700663308	
    Loss 845.760119212	
    Loss 849.23694322506	
    Loss 852.06629546259	
    Loss 861.02821894539	
    Loss 861.48847592329	
    Loss 856.21669751336	
    Loss 855.42999098742	
    Loss 860.01571234077	
Epoch 7	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4712929677729	
    Loss 848.98806122826	
    Loss 856.32451429007	
    Loss 862.90376176895	
    Loss 859.2049544486	
    Loss 859.35822789847	
    Loss 859.8673102124	
    Loss 858.07687951878	
    Loss 858.40976996838	
    Loss 866.73729011266	
    Loss 866.48115530607	
    Loss 866.58809537192	
    Loss 864.21717180852	
    Loss 854.07830346664	
    Loss 850.33746466934	
    Loss 852.36833578917	
    Loss 844.23490305724	
    Loss 853.6259885455	
    Loss 860.78504762457	
    Loss 856.60180531226	
    Loss 853.24787351947	
    Loss 857.7653162741	
    Loss 859.77955131036	
    Loss 864.06314378769	
    Loss 865.85965186123	
    Loss 859.65859299573	
    Loss 860.9276926425	
    Loss 854.45012186042	
    Loss 852.46057563284	
    Loss 853.22498325972	
    Loss 849.34714689733	
    Loss 857.69457027843	
    Loss 850.25929589907	
    Loss 856.34414432422	
    Loss 857.94168668146	
    Loss 857.01346923316	
    Loss 861.64346709968	
    Loss 859.69338851606	
    Loss 859.31267362331	
    Loss 859.79288671233	
    Loss 856.50461854184	
    Loss 866.37231698003	
    Loss 861.70538324276	
    Loss 855.56612422625	
    Loss 853.8340986226	
    Loss 862.04154725089	
    Loss 860.03947342479	
    Loss 861.27754149058	
    Loss 860.43408294873	
    Loss 854.63781642928	
    Loss 853.01041095307	
    Loss 849.28650141686	
    Loss 857.10370511809	
    Loss 853.49068065895	
    Loss 856.50840029293	
    Loss 859.01591442357	
    Loss 859.4239117438	
    Loss 856.86008498016	
    Loss 859.75764046473	
    Loss 864.3025039696	
    Loss 865.89716782409	
    Loss 856.43400037185	
    Loss 857.31937032352	
    Loss 862.11706935562	
    Loss 853.20640087389	
    Loss 856.61600618673	
    Loss 857.94237328512	
    Loss 861.88978643125	
    Loss 860.30568440534	
    Loss 855.02179688346	
    Loss 866.04105383854	
    Loss 864.61749307525	
    Loss 860.28301897235	
    Loss 857.94106216574	
    Loss 859.21242333671	
    Loss 858.1073614176	
    Loss 853.93855605935	
    Loss 851.8877906089	
    Loss 846.32044216564	
    Loss 850.88835698167	
    Loss 860.52040361319	
    Loss 856.17824897075	
    Loss 859.37879739188	
    Loss 850.82010643028	
    Loss 854.86383515963	
    Loss 863.83983556392	
    Loss 854.27916414019	
    Loss 845.47868074922	
    Loss 852.60455729342	
    Loss 851.79095814857	
    Loss 856.06522505154	
    Loss 858.26712195428	
    Loss 857.37061044536	
    Loss 857.92635312488	
    Loss 852.87139037162	
    Loss 847.57880925752	
    Loss 841.66378140691	
    Loss 842.44380247822	
    Loss 831.6186331053	
    Loss 836.86713975527	
    Loss 839.50482664265	
    Loss 848.56422198828	
    Loss 852.90999741909	
    Loss 854.26382212477	
    Loss 855.36740032462	
    Loss 862.2777687923	
    Loss 866.11208881832	
    Loss 856.93639320308	
    Loss 850.57302303598	
    Loss 857.56285413851	
    Loss 847.13405203348	
    Loss 851.34196627591	
    Loss 853.3074687352	
    Loss 848.53762166058	
    Loss 850.99584158242	
    Loss 852.72188017891	
    Loss 863.64331031243	
    Loss 855.75655553499	
    Loss 861.23189999829	
    Loss 859.90778797315	
    Loss 855.22729816808	
    Loss 852.51316281113	
    Loss 854.55588053834	
    Loss 851.50986910082	
    Loss 851.03764523495	
    Loss 850.67707413702	
    Loss 853.61487788361	
    Loss 852.93248683446	
    Loss 858.15846075192	
    Loss 861.08142932701	
    Loss 860.14594203724	
    Loss 859.58839735129	
    Loss 853.70503970132	
    Loss 844.59282546502	
    Loss 839.43038794616	
    Loss 841.8700663308	
    Loss 845.760119212	
    Loss 849.23694322507	
    Loss 852.06629546259	
    Loss 861.02821894539	
    Loss 861.48847592329	
    Loss 856.21669751336	
    Loss 855.42999098742	
    Loss 860.01571234077	
Epoch 8	
  5509
  2063
    70
     0
 41842
     0
     0
 15922
 61290
  4986
   126
[torch.DoubleTensor of size 11]

Validation accuracy:	0.090836671522214	
Grad norm	6.4712929677729	
    Loss 848.98806122826	
    Loss 856.32451429007	
    Loss 862.90376176895	
    Loss 859.2049544486	
    Loss 859.35822789847	
    Loss 859.8673102124	
    Loss 858.07687951878	
    Loss 858.40976996838	
    Loss 866.73729011266	
    Loss 866.48115530607	
    Loss 866.58809537192	
    Loss 864.21717180852	
    Loss 854.07830346664	
    Loss 850.33746466934	
    Loss 852.36833578917	
    Loss 844.23490305724	
    Loss 853.6259885455	
    Loss 860.78504762457	
    Loss 856.60180531226	
    Loss 853.24787351947	
    Loss 857.7653162741	
    Loss 859.77955131036	
    Loss 864.06314378769	
    Loss 865.85965186123	
    Loss 859.65859299573	
    Loss 860.9276926425	
    Loss 854.45012186042	
    Loss 852.46057563284	
    Loss 853.22498325972	
    Loss 849.34714689733	
    Loss 857.69457027843	
    Loss 850.25929589907	
    Loss 856.34414432422	
    Loss 857.94168668146	
    Loss 857.01346923316	
    Loss 861.64346709968	
    Loss 859.69338851606	
    Loss 859.31267362331	
    Loss 859.79288671233	
    Loss 856.50461854184	
    Loss 866.37231698003	
    Loss 861.70538324276	
    Loss 855.56612422625	
    Loss 853.8340986226	
    Loss 862.04154725089	
    Loss 860.03947342479	
    Loss 861.27754149058	
    Loss 860.43408294873	
    Loss 854.63781642928	
    Loss 853.01041095307	
    Loss 849.28650141686	
    Loss 857.10370511809	
    Loss 853.49068065895	
    Loss 856.50840029293	
    Loss 859.01591442357	
    Loss 859.4239117438	
    Loss 856.86008498016	
    Loss 859.75764046473	
    Loss 864.3025039696	
    Loss 865.89716782409	
    Loss 856.43400037185	
    Loss 857.31937032352	
