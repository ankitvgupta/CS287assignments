[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW2/PTB.hdf5	Classifier:	lr	Alpha:	5	Eta:	1	Lambda:	10	Minibatch size:	64	Num Epochs:	20	
nclasses:	45	nsparsefeatures:	101214	ndensefeatures:	3	
Imported all data	
Began logistic regression	
Got parameters	101214	3	45	
Set up ParallelTable	
Set up model	
Set up criterion	
Got params and grads	
Epoch 1	
 3085
 2425
 2592
 8295
  930
 1188
 3048
 1934
 6966
 7324
 3913
 2291
 3041
 2260
 2867
  836
  981
 2732
 7214
 6827
 1050
 1863
 4183
 1915
 2754
 1821
 2787
 1301
 3411
 2461
  855
 2839
 2104
 2120
 1333
 3837
 5232
 3819
 2508
 1075
 2031
 1623
 1254
 3184
 3699
[torch.DoubleTensor of size 45]

Validation accuracy:	0.023041090070405	
Grad norm	0	
    Loss 22759355.636975	
    Loss 19778600.182493	
    Loss 17188361.818361	
    Loss 14937333.542348	
    Loss 12981167.698022	
    Loss 11281193.003453	
    Loss 9803893.7469334	
    Loss 8520058.3585879	
    Loss 7404357.3939408	
    Loss 6434780.0997802	
    Loss 5592180.9018391	
    Loss 4859938.9441183	
    Loss 4223583.1009003	
    Loss 3670589.4546735	
    Loss 3190005.567322	
    Loss 2772368.3507913	
    Loss 2409414.922468	
    Loss 2093995.6326965	
    Loss 1819880.6828134	
    Loss 1581657.7075534	
    Loss 1374640.1386829	
    Loss 1194726.8908581	
    Loss 1038377.5050644	
    Loss 902507.83631829	
    Loss 784428.79233686	
    Loss 681816.71948241	
    Loss 592638.87567758	
    Loss 515139.67814666	
    Loss 447788.10837876	
    Loss 389255.85409799	
    Loss 338390.68835158	
    Loss 294185.66169716	
    Loss 255772.41126468	
    Loss 222386.60457385	
    Loss 193373.04327389	
    Loss 168157.05492059	
    Loss 146243.76260066	
    Loss 127199.39545203	
    Loss 110651.42125864	
    Loss 96268.137116459	
    Loss 83771.874434794	
    Loss 72909.525703253	
    Loss 63467.007970067	
    Loss 55265.978255136	
    Loss 48138.663474491	
    Loss 41943.212054696	
    Loss 36559.899588977	
    Loss 31879.951014651	
    Loss 27812.853684844	
    Loss 24277.005425728	
    Loss 21203.183793691	
    Loss 18537.43432578	
    Loss 16212.019760724	
    Loss 14200.66999564	
    Loss 12451.396734697	
    Loss 10931.363585085	
    Loss 9608.2522641517	
    Loss 8457.7050751815	
    Loss 7461.4075971793	
    Loss 6595.5604751418	
    Loss 5839.4200947073	
    Loss 5183.3820710962	
    Loss 4613.4832347642	
    Loss 4115.3870669229	
    Loss 3685.4579666367	
    Loss 3311.0625316209	
    Loss 2984.974687116	
    Loss 2703.9181901187	
    Loss 2456.030956789	
    Loss 2241.5617933091	
    Loss 2056.542198693	
    Loss 1894.9665164738	
    Loss 1753.3013837774	
    Loss 1631.18783419	
    Loss 1526.9699235526	
    Loss 1436.5040780425	
    Loss 1356.3593188501	
    Loss 1288.2742585359	
    Loss 1227.3422051184	
    Loss 1178.235575407	
    Loss 1130.0177505824	
    Loss 1091.5335618772	
    Loss 1054.7354260215	
    Loss 1025.4206053958	
    Loss 1002.8110950832	
    Loss 977.3509176623	
    Loss 954.1797919123	
    Loss 938.54731358737	
    Loss 922.06182411938	
    Loss 909.45560774786	
    Loss 902.14471340656	
    Loss 889.82889686726	
    Loss 885.79132002609	
    Loss 879.70246007872	
    Loss 867.30727563862	
    Loss 860.78732512972	
    Loss 856.31351772676	
    Loss 850.38320874473	
    Loss 847.36271662369	
    Loss 844.7842313674	
    Loss 842.94327202928	
    Loss 841.40419453643	
    Loss 838.2512952737	
    Loss 839.20916350056	
    Loss 838.18278943267	
    Loss 838.71519608903	
    Loss 836.51924529926	
    Loss 835.90805006145	
    Loss 835.77530589891	
    Loss 828.64276415229	
    Loss 830.34463537087	
    Loss 828.09773126567	
    Loss 828.26986147051	
    Loss 830.09768443891	
    Loss 832.51913145546	
    Loss 836.23830873179	
    Loss 834.35957236776	
    Loss 832.8906969871	
    Loss 832.99124089694	
    Loss 830.0571049492	
    Loss 833.14245877334	
    Loss 833.48142238261	
    Loss 832.44391108178	
    Loss 832.36403644772	
    Loss 830.7302520218	
    Loss 827.83841673609	
    Loss 825.87911130008	
    Loss 824.74455656241	
    Loss 829.29230550569	
    Loss 826.55101257966	
    Loss 824.14692791645	
    Loss 824.22485721056	
    Loss 824.24350256564	
    Loss 823.91459969096	
    Loss 827.25472061482	
    Loss 825.75041338089	
    Loss 825.50561781915	
    Loss 824.4479903202	
    Loss 825.46168266984	
    Loss 827.95143347036	
    Loss 825.82936859522	
    Loss 829.19155280576	
    Loss 827.3773909554	
Epoch 2	
 130705
      0
      0
      0
      0
      0
      0
      0
   1103
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.4588721947365	
    Loss 823.73911870092	
    Loss 822.72209722558	
    Loss 826.95066204339	
    Loss 826.52140360867	
    Loss 826.95783054965	
    Loss 826.16716824442	
    Loss 828.23233590029	
    Loss 824.0485375937	
    Loss 827.84954725174	
    Loss 827.95352381097	
    Loss 832.15196558586	
    Loss 830.16918428184	
    Loss 828.01501380446	
    Loss 826.9919595395	
    Loss 826.16689421942	
    Loss 826.87407765004	
    Loss 828.75685148871	
    Loss 830.41302641797	
    Loss 831.06396787638	
    Loss 829.96076886636	
    Loss 829.33072388018	
    Loss 831.86032889304	
    Loss 831.58457966646	
    Loss 831.81259164432	
    Loss 828.53840673704	
    Loss 828.94646792134	
    Loss 828.54420242837	
    Loss 826.94727829709	
    Loss 827.6868282938	
    Loss 827.98207736819	
    Loss 830.06294187757	
    Loss 828.65212936852	
    Loss 828.09270619065	
    Loss 827.56359920569	
    Loss 828.37709247496	
    Loss 828.40081908781	
    Loss 825.358631048	
    Loss 825.34848650966	
    Loss 827.33212469038	
    Loss 825.41488526086	
    Loss 826.70100964797	
    Loss 826.19841910975	
    Loss 823.28438056504	
    Loss 824.78783182613	
    Loss 826.45762287239	
    Loss 825.49229867803	
    Loss 826.69108631752	
    Loss 826.98797815912	
    Loss 826.54995635708	
    Loss 824.89246908141	
    Loss 821.93531698496	
    Loss 825.23117233227	
    Loss 818.84093432647	
    Loss 823.32560461775	
    Loss 825.79194888102	
    Loss 828.40260805604	
    Loss 828.06987385453	
    Loss 827.20952554493	
    Loss 830.18207262386	
    Loss 832.94620283999	
    Loss 831.33830222478	
    Loss 831.01458576874	
    Loss 830.90413220687	
    Loss 828.20396486956	
    Loss 828.80307446637	
    Loss 828.31997968519	
    Loss 827.43146538653	
    Loss 828.89035509284	
    Loss 826.45030816706	
    Loss 825.32588759032	
    Loss 825.62843892519	
    Loss 825.3647339785	
    Loss 823.88321417325	
    Loss 823.5689809437	
    Loss 825.0856227663	
    Loss 826.56647302768	
    Loss 826.35733061728	
    Loss 827.71359593606	
    Loss 827.16110851376	
    Loss 830.41821559153	
    Loss 827.76205631719	
    Loss 828.84638192478	
    Loss 826.46045963285	
    Loss 827.04253136297	
    Loss 830.41668029896	
    Loss 827.54573481585	
    Loss 824.03627550628	
    Loss 825.44746456928	
    Loss 823.74977510114	
    Loss 824.02730901412	
    Loss 827.92086062012	
    Loss 825.35223976714	
    Loss 829.75102397911	
    Loss 831.00280790107	
    Loss 825.00398554782	
    Loss 824.00137242116	
    Loss 824.31564920316	
    Loss 822.5846574579	
    Loss 823.18415911633	
    Loss 823.75367920844	
    Loss 824.66482024133	
    Loss 825.53788522252	
    Loss 824.46054385463	
    Loss 827.2262971842	
    Loss 827.76978548252	
    Loss 829.67394479716	
    Loss 828.65185583614	
    Loss 829.06676548904	
    Loss 829.83556558061	
    Loss 823.49475824222	
    Loss 825.86973622767	
    Loss 824.20576461345	
    Loss 824.89004171001	
    Loss 827.15913144758	
    Loss 829.96937483225	
    Loss 834.02097276413	
    Loss 832.43080403485	
    Loss 831.21521576513	
    Loss 831.53347378111	
    Loss 828.79067275233	
    Loss 832.0406665958	
    Loss 832.5269754269	
    Loss 831.61258569731	
    Loss 831.63942639336	
    Loss 830.10178587081	
    Loss 827.29460023207	
    Loss 825.40586021712	
    Loss 824.33136583241	
    Loss 828.93605975854	
    Loss 826.24256387954	
    Loss 823.87928451153	
    Loss 823.99223612067	
    Loss 824.04160961185	
    Loss 823.74057553372	
    Loss 827.10547434976	
    Loss 825.62077101503	
    Loss 825.39409411101	
    Loss 824.35234968587	
    Loss 825.3788609082	
    Loss 827.88003133834	
    Loss 825.76747630334	
    Loss 829.13807824345	
    Loss 827.33075446519	
Epoch 3	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.383073012605	
    Loss 823.69612061932	
    Loss 822.68486155358	
    Loss 826.91750752968	
    Loss 826.49327498579	
    Loss 826.9330606928	
    Loss 826.14603917816	
    Loss 828.21394249736	
    Loss 824.0327412718	
    Loss 827.83611089289	
    Loss 827.94208368425	
    Loss 832.14183535531	
    Loss 830.16022388325	
    Loss 828.00728934462	
    Loss 826.9851980316	
    Loss 826.1610195032	
    Loss 826.86877548116	
    Loss 828.75221896886	
    Loss 830.40888796016	
    Loss 831.06040066928	
    Loss 829.95783147732	
    Loss 829.32802815806	
    Loss 831.85812020057	
    Loss 831.5826111742	
    Loss 831.81081236806	
    Loss 828.53679836788	
    Loss 828.94497340199	
    Loss 828.54288591606	
    Loss 826.94604417867	
    Loss 827.68577350234	
    Loss 827.98122060743	
    Loss 830.06220757106	
    Loss 828.6514541802	
    Loss 828.09202611205	
    Loss 827.56299093274	
    Loss 828.37658636877	
    Loss 828.40043126689	
    Loss 825.35825758623	
    Loss 825.34822124278	
    Loss 827.33191648657	
    Loss 825.41470227911	
    Loss 826.70081556554	
    Loss 826.198262633	
    Loss 823.28426152139	
    Loss 824.78770595471	
    Loss 826.45750496043	
    Loss 825.49215831184	
    Loss 826.6909765253	
    Loss 826.98792490111	
    Loss 826.54992481238	
    Loss 824.89245590516	
    Loss 821.93530129207	
    Loss 825.23116502361	
    Loss 818.84091160354	
    Loss 823.32559282541	
    Loss 825.79194032748	
    Loss 828.40261593757	
    Loss 828.06988075698	
    Loss 827.2095318107	
    Loss 830.18208340174	
    Loss 832.94622282281	
    Loss 831.33831833496	
    Loss 831.0145973715	
    Loss 830.90413616276	
    Loss 828.20397048855	
    Loss 828.80308081849	
    Loss 828.31997966345	
    Loss 827.43146633978	
    Loss 828.890355406	
    Loss 826.45030546952	
    Loss 825.32588437354	
    Loss 825.62843254872	
    Loss 825.36473299798	
    Loss 823.88321763877	
    Loss 823.568987694	
    Loss 825.08562819028	
    Loss 826.56647874046	
    Loss 826.35733836284	
    Loss 827.71360406539	
    Loss 827.1611179432	
    Loss 830.41822219283	
    Loss 827.7620623362	
    Loss 828.84638719925	
    Loss 826.46046497044	
    Loss 827.04253589321	
    Loss 830.41668412344	
    Loss 827.54573911027	
    Loss 824.0362810108	
    Loss 825.44746957482	
    Loss 823.74977881948	
    Loss 824.02731279097	
    Loss 827.92086490951	
    Loss 825.35224443147	
    Loss 829.75102755433	
    Loss 831.0028110901	
    Loss 825.00398899088	
    Loss 824.00137441649	
    Loss 824.31564990484	
    Loss 822.58465831442	
    Loss 823.18415905225	
    Loss 823.7536783955	
    Loss 824.66481938264	
    Loss 825.53788510078	
    Loss 824.46054377084	
    Loss 827.22629718252	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560307	
    Loss 829.0667651247	
    Loss 829.83556544569	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191585	
    Loss 827.15913161195	
    Loss 829.96937515711	
    Loss 834.02097299384	
    Loss 832.43080422129	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280113	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.612585748	
    Loss 831.63942634924	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.3313657962	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619102	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428434	
    Loss 824.35234988494	
    Loss 825.37886108459	
    Loss 827.88003151447	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 4	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361604	
    Loss 823.69612073009	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374547	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237113	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060553	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160371	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 5	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 6	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.93306073809	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 7	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.93306073809	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 8	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899102	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377084	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 9	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899102	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 10	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.93306073809	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 11	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899103	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377085	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
    Loss 832.4308042213	
    Loss 831.21521589306	
    Loss 831.53347381315	
    Loss 828.79067280112	
    Loss 832.04066663599	
    Loss 832.52697559569	
    Loss 831.61258574801	
    Loss 831.63942634923	
    Loss 830.10178589372	
    Loss 827.29460032787	
    Loss 825.40586025521	
    Loss 824.33136579619	
    Loss 828.93605982703	
    Loss 826.24256397953	
    Loss 823.87928460699	
    Loss 823.99223619101	
    Loss 824.04160968647	
    Loss 823.74057564499	
    Loss 827.10547451384	
    Loss 825.62077116508	
    Loss 825.39409428435	
    Loss 824.35234988494	
    Loss 825.37886108461	
    Loss 827.88003151448	
    Loss 825.76747646426	
    Loss 829.13807839492	
    Loss 827.33075458869	
Epoch 12	
 130704
      0
      0
      0
      0
      0
      0
      0
   1104
[torch.DoubleTensor of size 9]

Validation accuracy:	0.098286902160719	
Grad norm	6.3830728361609	
    Loss 823.6961207301	
    Loss 822.68486164507	
    Loss 826.91750757726	
    Loss 826.49327505641	
    Loss 826.9330607381	
    Loss 826.14603923394	
    Loss 828.21394254517	
    Loss 824.032741321	
    Loss 827.83611094981	
    Loss 827.94208374548	
    Loss 832.1418354014	
    Loss 830.16022391427	
    Loss 828.00728937433	
    Loss 826.98519805687	
    Loss 826.16101952616	
    Loss 826.86877549533	
    Loss 828.75221898079	
    Loss 830.40888796536	
    Loss 831.06040067428	
    Loss 829.95783148801	
    Loss 829.32802816194	
    Loss 831.85812020898	
    Loss 831.58261117947	
    Loss 831.81081237114	
    Loss 828.53679836891	
    Loss 828.94497339971	
    Loss 828.54288591334	
    Loss 826.94604417273	
    Loss 827.68577349713	
    Loss 827.98122060554	
    Loss 830.06220756944	
    Loss 828.65145417757	
    Loss 828.09202610651	
    Loss 827.56299092685	
    Loss 828.37658636432	
    Loss 828.40043126531	
    Loss 825.35825758359	
    Loss 825.34822124301	
    Loss 827.33191648729	
    Loss 825.4147022797	
    Loss 826.70081556447	
    Loss 826.19826263262	
    Loss 823.2842615219	
    Loss 824.78770595423	
    Loss 826.45750495967	
    Loss 825.49215830972	
    Loss 826.690976524	
    Loss 826.98792490165	
    Loss 826.54992481338	
    Loss 824.8924559065	
    Loss 821.93530129302	
    Loss 825.23116502465	
    Loss 818.84091160372	
    Loss 823.32559282587	
    Loss 825.79194032793	
    Loss 828.40261593867	
    Loss 828.06988075804	
    Loss 827.2095318117	
    Loss 830.18208340289	
    Loss 832.94622282426	
    Loss 831.33831833619	
    Loss 831.01459737246	
    Loss 830.90413616334	
    Loss 828.20397048912	
    Loss 828.80308081902	
    Loss 828.31997966367	
    Loss 827.43146633996	
    Loss 828.89035540608	
    Loss 826.4503054695	
    Loss 825.32588437349	
    Loss 825.62843254856	
    Loss 825.364732998	
    Loss 823.88321763897	
    Loss 823.56898769432	
    Loss 825.08562819053	
    Loss 826.56647874071	
    Loss 826.35733836318	
    Loss 827.71360406574	
    Loss 827.1611179436	
    Loss 830.41822219312	
    Loss 827.76206233644	
    Loss 828.84638719949	
    Loss 826.4604649707	
    Loss 827.04253589339	
    Loss 830.41668412358	
    Loss 827.54573911044	
    Loss 824.03628101103	
    Loss 825.44746957502	
    Loss 823.74977881964	
    Loss 824.02731279113	
    Loss 827.9208649097	
    Loss 825.35224443166	
    Loss 829.75102755449	
    Loss 831.00281109025	
    Loss 825.00398899102	
    Loss 824.00137441657	
    Loss 824.31564990489	
    Loss 822.58465831445	
    Loss 823.18415905224	
    Loss 823.75367839545	
    Loss 824.6648193826	
    Loss 825.53788510078	
    Loss 824.46054377084	
    Loss 827.22629718251	
    Loss 827.76978548306	
    Loss 829.67394502309	
    Loss 828.65185560304	
    Loss 829.06676512467	
    Loss 829.83556544567	
    Loss 823.49475856041	
    Loss 825.86973646077	
    Loss 824.20576467677	
    Loss 824.89004191587	
    Loss 827.15913161196	
    Loss 829.96937515711	
    Loss 834.02097299386	
