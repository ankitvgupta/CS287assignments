[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	16	embedding_size:	35	optimizer:	adagrad	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
 599905
[torch.LongStorage of size 1]

 599905
[torch.LongStorage of size 1]

 95823
[torch.LongStorage of size 1]

RNN	
Unit1: LSTM added	
Dropout added	0.25	
Unit2: LSTM added	
Beginning epoch	1	
    	11.060063414596	
Beginning epoch	2	
    	4.2917492483448	
Beginning epoch	3	
    	3.9165961635676	
Beginning epoch	4	
    	4.2836597393955	
Beginning epoch	5	
    	4.3998207053367	
Beginning epoch	6	
    	4.3527629926444	
Beginning epoch	7	
    	3.9099825948873	
Beginning epoch	8	
    	3.6918245273971	
Beginning epoch	9	
    	4.0371869557953	
Beginning epoch	10	
    	4.119644614611	
Beginning epoch	11	
    	3.9895352061276	
Beginning epoch	12	
    	4.2608184697539	
Beginning epoch	13	
    	4.1984600507932	
Beginning epoch	14	
    	4.1927968857077	
Beginning epoch	15	
    	4.1120784684698	
Beginning epoch	16	
    	4.2485327415961	
Beginning epoch	17	
    	4.1146290841116	
Beginning epoch	18	
    	3.985755755751	
Beginning epoch	19	
    	3.7180727996279	
Beginning epoch	20	
    	3.8927711599121	
Beginning epoch	21	
    	4.3115543958034	
Beginning epoch	22	
    	4.3085464614651	
Beginning epoch	23	
    	4.4980564694822	
Beginning epoch	24	
    	4.1080909178129	
Beginning epoch	25	
    	4.2163754462398	
Beginning epoch	26	
    	4.5063977244623	
Beginning epoch	27	
    	4.9241340035337	
Beginning epoch	28	
    	4.810382693372	
Beginning epoch	29	
    	4.9623432902712	
Beginning epoch	30	
    	5.0908171550601	
Beginning epoch	31	
    	4.9925539016397	
Beginning epoch	32	
    	4.6813432475553	
Beginning epoch	33	
    	5.1248221671068	
Beginning epoch	34	
    	5.6881382721437	
Beginning epoch	35	
    	5.9743334379822	
Beginning epoch	36	
    	6.1941131644898	
Beginning epoch	37	
    	5.6826412240948	
Beginning epoch	38	
    	5.4363367853313	
Beginning epoch	39	
    	5.568994366824	
Beginning epoch	40	
    	6.5168392944284	
Beginning epoch	41	
    	7.1248702539746	
Beginning epoch	42	
    	7.2164657401138	
Beginning epoch	43	
    	7.2616904275608	
Beginning epoch	44	
    	10.152771680077	
Beginning epoch	45	
    	8.5000810141008	
Beginning epoch	46	
    	7.6941771046378	
Beginning epoch	47	
    	8.4008369887134	
Beginning epoch	48	
    	7.6909586714623	
Beginning epoch	49	
    	8.6054774417707	
Beginning epoch	50	
    	9.098829914489	
Word	1000	
Word	1000	
Word	2000	
Word	3000	
Word	4000	
Word	5000	
Word	6000	
Word	7000	
Word	7000	
Word	8000	
Word	8000	
Word	9000	
Word	10000	
Word	10000	
Word	11000	
Word	12000	
Word	12000	
Word	13000	
Word	14000	
Word	15000	
Word	16000	
Word	17000	
Word	18000	
Word	18000	
Word	19000	
Word	20000	
Word	21000	
Word	22000	
Word	23000	
Word	24000	
Word	24000	
Word	25000	
Word	25000	
Word	26000	
Word	26000	
Word	27000	
Word	28000	
Word	29000	
Word	30000	
Word	31000	
Word	31000	
Word	32000	
Word	33000	
Word	34000	
Word	35000	
Word	36000	
Word	37000	
Word	38000	
Word	39000	
Word	40000	
Word	40000	
Word	41000	
Word	42000	
Word	42000	
Word	43000	
Word	44000	
Word	44000	
Word	45000	
Word	45000	
Word	46000	
Word	47000	
Word	48000	
Word	49000	
Word	50000	
Word	50000	
Word	51000	
Word	51000	
Word	52000	
Word	53000	
Word	54000	
Word	54000	
Word	55000	
Word	56000	
Word	57000	
Word	58000	
Word	58000	
Word	59000	
Word	60000	
Word	61000	
Word	62000	
Word	63000	
Word	64000	
Word	65000	
Word	66000	
Word	67000	
Word	68000	
Word	69000	
Word	70000	
Word	71000	
Word	72000	
Word	73000	
Word	74000	
Word	75000	
Word	76000	
Word	76000	
Word	77000	
Word	78000	
Word	79000	
Word	80000	
Word	81000	
Word	82000	
Word	83000	
Word	83000	
Word	84000	
Word	85000	
Word	86000	
Word	87000	
Word	88000	
Word	89000	
Word	90000	
Word	91000	
Word	92000	
Word	93000	
Word	94000	
Word	95000	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	16	embedding_size:	35	optimizer:	adagrad	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
Results:	0.87147135865085	0.71630031401656	0.63067410646961	13.888427299703	
