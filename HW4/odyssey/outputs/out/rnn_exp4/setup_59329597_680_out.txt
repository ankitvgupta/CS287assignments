[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	32	embedding_size:	35	optimizer:	sgd	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
 599905
[torch.LongStorage of size 1]

 599905
[torch.LongStorage of size 1]

 95823
[torch.LongStorage of size 1]

RNN	
Unit1: LSTM added	
Dropout added	0.25	
Unit2: LSTM added	
Beginning epoch	1	
    	21.234891737903	
Beginning epoch	2	
    	13.087815416838	
Beginning epoch	3	
    	10.623159134075	
Beginning epoch	4	
    	9.3549570264032	
Beginning epoch	5	
    	8.647758833014	
Beginning epoch	6	
    	8.0937647908863	
Beginning epoch	7	
    	7.8184430921458	
Beginning epoch	8	
    	7.5298585843978	
Beginning epoch	9	
    	7.4314783458949	
Beginning epoch	10	
    	7.2639545625605	
Beginning epoch	11	
    	7.1537533658571	
Beginning epoch	12	
    	7.1709010578367	
Beginning epoch	13	
    	7.0293082400392	
Beginning epoch	14	
    	7.1010906059221	
Beginning epoch	15	
    	6.7514500138989	
Beginning epoch	16	
    	6.9789862561935	
Beginning epoch	17	
    	6.796513417186	
Beginning epoch	18	
    	6.6071859470697	
Beginning epoch	19	
    	6.5083195211334	
Beginning epoch	20	
    	6.3492693381737	
Beginning epoch	21	
    	6.3852534679076	
Beginning epoch	22	
    	6.3629404517053	
Beginning epoch	23	
    	6.1900857245716	
Beginning epoch	24	
    	6.3320947624676	
Beginning epoch	25	
    	6.1141735627993	
Beginning epoch	26	
    	6.3406284046954	
Beginning epoch	27	
    	6.2275459628008	
Beginning epoch	28	
    	6.1390469814808	
Beginning epoch	29	
    	6.011383558487	
Beginning epoch	30	
    	6.0611910166974	
Beginning epoch	31	
    	6.0158266255752	
Beginning epoch	32	
    	6.135248070804	
Beginning epoch	33	
    	6.0202882112365	
Beginning epoch	34	
    	5.9919001486181	
Beginning epoch	35	
    	5.9482258228348	
Beginning epoch	36	
    	6.0461383922905	
Beginning epoch	37	
    	6.0419825180982	
Beginning epoch	38	
    	5.9971868332506	
Beginning epoch	39	
    	6.2766366984208	
Beginning epoch	40	
    	5.9049721769997	
Beginning epoch	41	
    	5.6843342183324	
Beginning epoch	42	
    	5.7155818528902	
Beginning epoch	43	
    	5.7978888098969	
Beginning epoch	44	
    	5.9547738322088	
Beginning epoch	45	
    	5.8887262815824	
Beginning epoch	46	
    	5.8927004523471	
Beginning epoch	47	
    	5.7967783124199	
Beginning epoch	48	
    	5.6312669371663	
Beginning epoch	49	
    	5.7714576204526	
Beginning epoch	50	
    	5.7074361497965	
Word	1000	
Word	1000	
Word	2000	
Word	3000	
Word	4000	
Word	4000	
Word	5000	
Word	6000	
Word	7000	
Word	7000	
Word	8000	
Word	9000	
Word	10000	
Word	10000	
Word	11000	
Word	12000	
Word	13000	
Word	13000	
Word	14000	
Word	15000	
Word	16000	
Word	16000	
Word	17000	
Word	18000	
Word	19000	
Word	20000	
Word	21000	
Word	22000	
Word	23000	
Word	24000	
Word	24000	
Word	25000	
Word	25000	
Word	26000	
Word	27000	
Word	28000	
Word	28000	
Word	29000	
Word	30000	
Word	31000	
Word	32000	
Word	33000	
Word	34000	
Word	35000	
Word	36000	
Word	37000	
Word	38000	
Word	38000	
Word	39000	
Word	40000	
Word	40000	
Word	41000	
Word	42000	
Word	42000	
Word	43000	
Word	44000	
Word	44000	
Word	45000	
Word	45000	
Word	46000	
Word	47000	
Word	48000	
Word	49000	
Word	50000	
Word	50000	
Word	51000	
Word	51000	
Word	52000	
Word	53000	
Word	54000	
Word	54000	
Word	55000	
Word	56000	
Word	57000	
Word	58000	
Word	59000	
Word	60000	
Word	61000	
Word	62000	
Word	63000	
Word	64000	
Word	65000	
Word	66000	
Word	67000	
Word	68000	
Word	69000	
Word	70000	
Word	71000	
Word	72000	
Word	73000	
Word	74000	
Word	75000	
Word	76000	
Word	77000	
Word	78000	
Word	79000	
Word	80000	
Word	80000	
Word	81000	
Word	82000	
Word	83000	
Word	83000	
Word	84000	
Word	85000	
Word	85000	
Word	86000	
Word	87000	
Word	88000	
Word	89000	
Word	90000	
Word	91000	
Word	92000	
Word	93000	
Word	94000	
Word	94000	
Word	95000	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	32	embedding_size:	35	optimizer:	sgd	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
Results:	0.87596923494359	0.72856490466948	0.64158246619414	12.054896142433	
