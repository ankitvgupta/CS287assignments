[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	32	alpha:	1	sequence_length:	16	embedding_size:	55	optimizer:	sgd	epochs:	50	hidden	15	eta:	0.1	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
 599905
[torch.LongStorage of size 1]

 599905
[torch.LongStorage of size 1]

 95823
[torch.LongStorage of size 1]

RNN	
Unit1: LSTM added	
Dropout added	0.25	
Unit2: LSTM added	
Beginning epoch	1	
    	10.496970483927	
Beginning epoch	2	
    	3.576382791299	
Beginning epoch	3	
    	3.3667762222766	
Beginning epoch	4	
    	3.6218189086346	
Beginning epoch	5	
    	3.6113330854752	
Beginning epoch	6	
    	3.7901671190348	
Beginning epoch	7	
    	3.4546324468975	
Beginning epoch	8	
    	3.5264219089387	
Beginning epoch	9	
    	3.5051753308235	
Beginning epoch	10	
    	3.3143270172921	
Beginning epoch	11	
    	3.4513820624279	
Beginning epoch	12	
    	3.5106177986464	
Beginning epoch	13	
    	3.5661664886768	
Beginning epoch	14	
    	3.4952083550584	
Beginning epoch	15	
    	3.4460348105073	
Beginning epoch	16	
    	3.6702967743198	
Beginning epoch	17	
    	3.5058842899476	
Beginning epoch	18	
    	3.6424686312116	
Beginning epoch	19	
    	3.7214334900978	
Beginning epoch	20	
    	3.4989354973233	
Beginning epoch	21	
    	3.2512980916683	
Beginning epoch	22	
    	3.4689042036894	
Beginning epoch	23	
    	3.4857059745203	
Beginning epoch	24	
    	3.7070276444063	
Beginning epoch	25	
    	3.4551483701889	
Beginning epoch	26	
    	3.4557975431677	
Beginning epoch	27	
    	3.5959248389249	
Beginning epoch	28	
    	3.5230829413429	
Beginning epoch	29	
    	3.3695436688884	
Beginning epoch	30	
    	3.3710398790604	
Beginning epoch	31	
    	3.651344219564	
Beginning epoch	32	
    	3.5253650880387	
Beginning epoch	33	
    	3.5665544334039	
Beginning epoch	34	
    	3.4305727517959	
Beginning epoch	35	
    	3.5378066409748	
Beginning epoch	36	
    	3.329533642785	
Beginning epoch	37	
    	3.5001096719937	
Beginning epoch	38	
    	3.4824804231143	
Beginning epoch	39	
    	3.0198606883526	
Beginning epoch	40	
    	3.2611184216349	
Beginning epoch	41	
    	3.5860054199184	
Beginning epoch	42	
    	3.5260643535921	
Beginning epoch	43	
    	3.3238034862509	
Beginning epoch	44	
    	3.2474677446019	
Beginning epoch	45	
    	3.0912620503208	
Beginning epoch	46	
    	3.2564757856074	
Beginning epoch	47	
    	3.2239748493818	
Beginning epoch	48	
    	3.2110376574431	
Beginning epoch	49	
    	3.4633538074219	
Beginning epoch	50	
    	3.4607254281625	
Word	1000	
Word	2000	
Word	3000	
Word	4000	
Word	5000	
Word	6000	
Word	7000	
Word	7000	
Word	8000	
Word	9000	
Word	10000	
Word	10000	
Word	11000	
Word	12000	
Word	13000	
Word	14000	
Word	14000	
Word	15000	
Word	16000	
Word	16000	
Word	17000	
Word	18000	
Word	18000	
Word	19000	
Word	20000	
Word	21000	
Word	21000	
Word	22000	
Word	23000	
Word	24000	
Word	24000	
Word	25000	
Word	25000	
Word	26000	
Word	27000	
Word	28000	
Word	29000	
Word	30000	
Word	31000	
Word	32000	
Word	33000	
Word	34000	
Word	35000	
Word	36000	
Word	37000	
Word	38000	
Word	39000	
Word	40000	
Word	40000	
Word	41000	
Word	42000	
Word	42000	
Word	43000	
Word	44000	
Word	44000	
Word	45000	
Word	45000	
Word	46000	
Word	47000	
Word	48000	
Word	49000	
Word	50000	
Word	50000	
Word	51000	
Word	51000	
Word	52000	
Word	53000	
Word	54000	
Word	54000	
Word	55000	
Word	56000	
Word	57000	
Word	58000	
Word	59000	
Word	60000	
Word	61000	
Word	62000	
Word	63000	
Word	64000	
Word	65000	
Word	66000	
Word	67000	
Word	68000	
Word	69000	
Word	70000	
Word	71000	
Word	72000	
Word	73000	
Word	74000	
Word	75000	
Word	76000	
Word	76000	
Word	77000	
Word	77000	
Word	78000	
Word	79000	
Word	80000	
Word	80000	
Word	81000	
Word	82000	
Word	83000	
Word	83000	
Word	84000	
Word	85000	
Word	85000	
Word	86000	
Word	87000	
Word	88000	
Word	89000	
Word	90000	
Word	91000	
Word	92000	
Word	93000	
Word	94000	
Word	94000	
Word	95000	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	32	alpha:	1	sequence_length:	16	embedding_size:	55	optimizer:	sgd	epochs:	50	hidden	15	eta:	0.1	hacks	false	rnn1	lstm	rnn2	lstm	dropout	0.25	
Results:	0.88786616991745	0.73716685678731	0.71467350324235	6.2611275964392	
