[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	16	embedding_size:	35	optimizer:	adagrad	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	gru	rnn2	lstm	dropout	0.25	
 599905
[torch.LongStorage of size 1]

 599905
[torch.LongStorage of size 1]

 95823
[torch.LongStorage of size 1]

RNN	
Unit1: GRU added	
Dropout added	0.25	
Unit2: LSTM added	
Beginning epoch	1	
    	11.304066719495	
Beginning epoch	2	
    	4.0498753392713	
Beginning epoch	3	
    	4.0890959012118	
Beginning epoch	4	
    	4.1540044336473	
Beginning epoch	5	
    	4.1098071661383	
Beginning epoch	6	
    	4.0613995008521	
Beginning epoch	7	
    	3.7503037827616	
Beginning epoch	8	
    	4.1880196250304	
Beginning epoch	9	
    	4.3280638512654	
Beginning epoch	10	
    	4.0685506752729	
Beginning epoch	11	
    	3.9037524164034	
Beginning epoch	12	
    	4.1700074922261	
Beginning epoch	13	
    	4.466857584695	
Beginning epoch	14	
    	3.9629419483112	
Beginning epoch	15	
    	4.0546554609428	
Beginning epoch	16	
    	4.2728064071515	
Beginning epoch	17	
    	4.3532980126327	
Beginning epoch	18	
    	4.0161909907604	
Beginning epoch	19	
    	4.3186885221467	
Beginning epoch	20	
    	4.4638620766172	
Beginning epoch	21	
    	4.2700099470952	
Beginning epoch	22	
    	4.2944802061721	
Beginning epoch	23	
    	4.3618723971945	
Beginning epoch	24	
    	4.5076848513373	
Beginning epoch	25	
    	4.2118254128529	
Beginning epoch	26	
    	4.4687254325213	
Beginning epoch	27	
    	4.4270916499912	
Beginning epoch	28	
    	4.1715782753837	
Beginning epoch	29	
    	4.2339325220266	
Beginning epoch	30	
    	4.2711573021909	
Beginning epoch	31	
    	4.4033481397495	
Beginning epoch	32	
    	4.3117002002673	
Beginning epoch	33	
    	4.4202460946392	
Beginning epoch	34	
    	4.0841577403912	
Beginning epoch	35	
    	4.6087658279847	
Beginning epoch	36	
    	4.257521043031	
Beginning epoch	37	
    	4.611334749437	
Beginning epoch	38	
    	4.502015727641	
Beginning epoch	39	
    	4.7634424869653	
Beginning epoch	40	
    	4.3291712203044	
Beginning epoch	41	
    	4.5155446419818	
Beginning epoch	42	
    	4.2613344313599	
Beginning epoch	43	
    	4.5343653600854	
Beginning epoch	44	
    	4.4039527206884	
Beginning epoch	45	
    	4.7378845913903	
Beginning epoch	46	
    	4.3888045041041	
Beginning epoch	47	
    	4.2976393206044	
Beginning epoch	48	
    	4.1337990639967	
Beginning epoch	49	
    	4.1811320692988	
Beginning epoch	50	
    	4.3110336640817	
Word	1000	
Word	2000	
Word	3000	
Word	4000	
Word	4000	
Word	5000	
Word	6000	
Word	7000	
Word	7000	
Word	8000	
Word	9000	
Word	10000	
Word	10000	
Word	11000	
Word	12000	
Word	12000	
Word	13000	
Word	14000	
Word	15000	
Word	16000	
Word	17000	
Word	18000	
Word	18000	
Word	19000	
Word	20000	
Word	21000	
Word	21000	
Word	22000	
Word	23000	
Word	24000	
Word	24000	
Word	25000	
Word	25000	
Word	26000	
Word	27000	
Word	28000	
Word	29000	
Word	30000	
Word	31000	
Word	32000	
Word	33000	
Word	34000	
Word	35000	
Word	36000	
Word	37000	
Word	38000	
Word	39000	
Word	40000	
Word	40000	
Word	41000	
Word	42000	
Word	42000	
Word	43000	
Word	44000	
Word	44000	
Word	45000	
Word	45000	
Word	46000	
Word	47000	
Word	48000	
Word	49000	
Word	50000	
Word	50000	
Word	51000	
Word	51000	
Word	52000	
Word	53000	
Word	54000	
Word	54000	
Word	55000	
Word	56000	
Word	57000	
Word	58000	
Word	59000	
Word	60000	
Word	61000	
Word	62000	
Word	63000	
Word	64000	
Word	65000	
Word	66000	
Word	67000	
Word	68000	
Word	69000	
Word	70000	
Word	71000	
Word	72000	
Word	73000	
Word	74000	
Word	75000	
Word	76000	
Word	77000	
Word	77000	
Word	78000	
Word	79000	
Word	80000	
Word	80000	
Word	81000	
Word	82000	
Word	83000	
Word	83000	
Word	84000	
Word	85000	
Word	85000	
Word	86000	
Word	87000	
Word	88000	
Word	89000	
Word	90000	
Word	91000	
Word	92000	
Word	93000	
Word	94000	
Word	94000	
Word	95000	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW4/PTB.hdf5	classifier:	rnn	window_size:	2	b:	64	alpha:	1	sequence_length:	16	embedding_size:	35	optimizer:	adagrad	epochs:	50	hidden	15	eta:	0.01	hacks	false	rnn1	gru	rnn2	lstm	dropout	0.25	
Results:	0.86363399183912	0.69363440372177	0.61458804604635	13.812462908012	
