[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	200	embedding_size	200	optimizer:	sgd	epochs:	600	hidden	200	eta:	0.05	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83200
[torch.LongStorage of size 2]

Using cuda	
 1183318
       1
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> output]
  (1): nn.LookupTable
  (2): nn.Transpose
  (3): nn.SplitTable
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(200 -> 200)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(200 -> 200)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(400 -> 200)
  (7): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (8): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (9): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 10)
  (10): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9244	
Max train index	23	
Num samples	9244	
Epoch	1	1	462.91326856613	
Epoch	1	462.91326856613	
Epoch	1	201	439.33170390129	
Epoch	1	401	417.94025468826	
Epoch	1	601	397.49099719524	
Epoch	1	801	375.09225440025	
Epoch	1	1001	359.29717993736	
Epoch	1	1201	347.84927201271	
Epoch	1	1401	336.59116327763	
Epoch	1	1601	336.45773506165	
Epoch	1	1801	332.48911106586	
Epoch	1	2001	322.62161970139	
Epoch	1	2201	324.33446574211	
Epoch	1	2401	328.56835460663	
Epoch	1	2601	323.75281834602	
Epoch	1	2801	320.15045487881	
Epoch	1	3001	322.39964020252	
Epoch	1	3201	323.27074205875	
Epoch	1	3401	320.73569965363	
Epoch	1	3601	315.57869148254	
Epoch	1	3801	319.19765901566	
Epoch	1	4001	322.40564060211	
Epoch	1	4201	318.08095622063	
Epoch	1	4401	318.31824731827	
Epoch	1	4601	316.48595321178	
Epoch	1	4801	312.79933702946	
Epoch	1	5001	316.21375513077	
Epoch	1	5201	310.09852433205	
Epoch	1	5401	314.36159801483	
Epoch	1	5601	309.64478564262	
Epoch	1	5801	312.02312207222	
Epoch	1	6001	310.34660232067	
Epoch	1	6201	309.35754489899	
Epoch	1	6401	308.91875600815	
Epoch	1	6601	313.73121726513	
Epoch	1	6801	306.41957306862	
Epoch	1	7001	308.33997893333	
Epoch	1	7201	302.90096139908	
Epoch	1	7401	308.28235960007	
Epoch	1	7601	311.08218181133	
Epoch	1	7801	309.58938980103	
Epoch	1	8001	301.2872146368	
Epoch	1	8201	309.43948853016	
Epoch	1	8401	298.4358907938	
Epoch	1	8601	307.78068828583	
Epoch	1	8801	307.70478188992	
Epoch	1	9001	306.44413757324	
Epoch	2	1	304.07273161411	
Epoch	2	304.07273161411	
Epoch	2	201	307.80254340172	
Epoch	2	401	308.54787671566	
