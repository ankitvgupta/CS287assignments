[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	15	optimizer:	adagrad	epochs:	200	hidden	10	eta:	0.001	rnn_unit1	lstm	rnn_unit2	none	dropout	0.5	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83300
[torch.LongStorage of size 2]

Using cuda	
 1183318
       1
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

Unit1: LSTM added	
No unit 2	
Converted LSTM to CUDA	
Converted crit to CUDA	
Input size	9244	
Max train index	23	
Epoch	1	226.47855734825	
Epoch	2	170.86383974552	
Epoch	3	158.72161781788	
Epoch	4	154.61896657944	
Epoch	5	152.8904132843	
Epoch	6	152.14395856857	
Epoch	7	151.64559316635	
Epoch	8	151.21724748611	
Epoch	9	150.78791558743	
Epoch	10	150.35789358616	
Epoch	11	150.00757157803	
Epoch	12	149.79068207741	
Epoch	13	149.64985883236	
Epoch	14	149.5290415287	
Epoch	15	149.443826437	
Epoch	16	149.38156223297	
Epoch	17	149.32449054718	
Epoch	18	149.25877583027	
Epoch	19	149.19758081436	
Epoch	20	149.07551622391	
Epoch	21	148.89821970463	
Epoch	22	148.66898500919	
Epoch	23	148.4967443943	
Epoch	24	148.4143859148	
Epoch	25	148.54283845425	
Epoch	26	148.11041200161	
Epoch	27	147.96360778809	
Epoch	28	147.76500308514	
Epoch	29	147.6886588335	
Epoch	30	147.56584060192	
Epoch	31	147.58961057663	
Epoch	32	147.51107621193	
Epoch	33	147.52163803577	
Epoch	34	147.35717689991	
Epoch	35	147.25944268703	
Epoch	36	147.1306732893	
Epoch	37	147.0627374649	
Epoch	38	147.0317274332	
Epoch	39	146.95628762245	
Epoch	40	147.38961422443	
Epoch	41	146.90844559669	
Epoch	42	146.7655377388	
Epoch	43	146.54962396622	
Epoch	44	146.6659630537	
Epoch	45	146.22985422611	
Epoch	46	146.44664824009	
Epoch	47	146.44823241234	
Epoch	48	146.08060348034	
Epoch	49	146.31304073334	
Epoch	50	146.22649478912	
Epoch	51	146.09236264229	
Epoch	52	146.1011749506	
Epoch	53	145.64286255836	
Epoch	54	145.89350223541	
Epoch	55	145.92957103252	
Epoch	56	145.84175753593	
Epoch	57	145.81853079796	
Epoch	58	145.7344571352	
Epoch	59	145.74657046795	
Epoch	60	145.72871351242	
Epoch	61	145.67943513393	
Epoch	62	145.70373296738	
Epoch	63	146.09453845024	
Epoch	64	145.65078830719	
Epoch	65	145.56044220924	
Epoch	66	145.52561759949	
Epoch	67	145.48381733894	
Epoch	68	145.54609751701	
Epoch	69	145.46245574951	
Epoch	70	145.53364157677	
Epoch	71	145.54793059826	
Epoch	72	145.44457113743	
Epoch	73	145.42820036411	
Epoch	74	145.42680358887	
Epoch	75	145.45474255085	
Epoch	76	145.32008981705	
Epoch	77	145.08147799969	
Epoch	78	145.35570979118	
Epoch	79	145.34947943687	
Epoch	80	145.41594266891	
Epoch	81	145.38459026814	
Epoch	82	145.39624273777	
Epoch	83	145.28591787815	
Epoch	84	145.34748494625	
Epoch	85	145.4664478302	
Epoch	86	145.07722699642	
Epoch	87	145.40748107433	
Epoch	88	146.57198214531	
Epoch	89	145.39417982101	
Epoch	90	145.26314342022	
Epoch	91	145.28050851822	
Epoch	92	145.19961309433	
Epoch	93	145.26053202152	
Epoch	94	145.2448387146	
Epoch	95	145.39376378059	
Epoch	96	145.34573805332	
Epoch	97	145.09311676025	
Epoch	98	145.25374436378	
Epoch	99	145.25725400448	
Epoch	100	145.24752104282	
Epoch	101	144.90657126904	
Epoch	102	145.1617013216	
Epoch	103	145.28740298748	
Epoch	104	145.27098035812	
Epoch	105	145.31120717525	
Epoch	106	145.29483985901	
Epoch	107	145.34305310249	
Epoch	108	145.27181243896	
Epoch	109	145.26100087166	
Epoch	110	145.24903178215	
Epoch	111	145.13476991653	
Epoch	112	145.15018689632	
Epoch	113	145.18867456913	
Epoch	114	145.11393535137	
Epoch	115	145.08469963074	
Epoch	116	146.18247020245	
Epoch	117	145.10151529312	
Epoch	118	146.23267197609	
Epoch	119	145.66392362118	
Epoch	120	144.72921848297	
Epoch	121	145.0421860218	
Epoch	122	145.13865923882	
Epoch	123	144.99874126911	
Epoch	124	145.07819652557	
Epoch	125	145.11593329906	
Epoch	126	145.11722505093	
Epoch	127	145.12820315361	
Epoch	128	145.05323815346	
Epoch	129	145.03831136227	
Epoch	130	145.13982343674	
Epoch	131	145.09642839432	
Epoch	132	145.12221539021	
Epoch	133	145.07973062992	
Epoch	134	145.0553034544	
Epoch	135	144.83120679855	
Epoch	136	144.65206670761	
Epoch	137	144.92032408714	
Epoch	138	144.8949649334	
Epoch	139	144.64471077919	
Epoch	140	144.75233495235	
Epoch	141	145.0269266367	
Epoch	142	145.01982092857	
Epoch	143	145.04470026493	
Epoch	144	145.05561161041	
Epoch	145	145.00918722153	
Epoch	146	144.98475301266	
Epoch	147	144.9978582859	
Epoch	148	144.80381512642	
Epoch	149	144.92292284966	
Epoch	150	144.74305450916	
Epoch	151	144.89866518974	
Epoch	152	144.81038331985	
Epoch	153	144.94717407227	
Epoch	154	145.45482695103	
Epoch	155	144.87776899338	
Epoch	156	144.87584650517	
Epoch	157	144.8235001564	
Epoch	158	144.97428846359	
Epoch	159	144.93984210491	
Epoch	160	144.8618183136	
Epoch	161	144.87256753445	
Epoch	162	144.84244704247	
Epoch	163	144.90653300285	
Epoch	164	144.98622357845	
Epoch	165	144.85249018669	
Epoch	166	144.57598102093	
Epoch	167	144.65918588638	
Epoch	168	144.961124897	
Epoch	169	144.92717170715	
Epoch	170	144.84277045727	
Epoch	171	144.85489368439	
Epoch	172	144.89295125008	
Epoch	173	144.88231635094	
Epoch	174	144.62348628044	
Epoch	175	144.93628275394	
Epoch	176	144.93716287613	
Epoch	177	144.85581338406	
Epoch	178	144.88943815231	
Epoch	179	144.87647974491	
Epoch	180	144.87331473827	
Epoch	181	144.85267603397	
Epoch	182	144.85187780857	
Epoch	183	144.86252629757	
Epoch	184	144.93110525608	
Epoch	185	144.8460226059	
Epoch	186	144.49032402039	
Epoch	187	145.01205122471	
Epoch	188	144.86329913139	
Epoch	189	144.54285538197	
Epoch	190	145.05771923065	
Epoch	191	144.9295425415	
Epoch	192	144.91754150391	
Epoch	193	144.88375115395	
Epoch	194	144.52210736275	
Epoch	195	144.56754505634	
Epoch	196	144.5580675602	
Epoch	197	144.8952293396	
Epoch	198	144.91346633434	
Epoch	199	144.89321208	
Epoch	200	144.89586400986	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	15	optimizer:	adagrad	epochs:	200	hidden	10	eta:	0.001	rnn_unit1	lstm	rnn_unit2	none	dropout	0.5	
Accuracy	0.43180072028812	
