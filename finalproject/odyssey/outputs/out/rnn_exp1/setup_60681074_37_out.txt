[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	15	optimizer:	adagrad	epochs:	200	hidden	10	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83350
[torch.LongStorage of size 2]

Using cuda	
 1183318
       1
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

Unit1: LSTM added	
Dropout added	0.5	
Unit2: LSTM added	
Converted LSTM to CUDA	
Converted crit to CUDA	
Input size	9244	
Max train index	23	
Epoch	1	116.55073523521	
Epoch	2	78.309371352196	
Epoch	3	77.418501496315	
Epoch	4	76.851866722107	
Epoch	5	75.596334934235	
Epoch	6	74.747578024864	
Epoch	7	75.431590795517	
Epoch	8	75.90378677845	
Epoch	9	75.462246894836	
Epoch	10	75.563370227814	
Epoch	11	74.712993144989	
Epoch	12	74.725360155106	
Epoch	13	75.181165456772	
Epoch	14	74.850488901138	
Epoch	15	76.583016395569	
Epoch	16	75.796246886253	
Epoch	17	75.275325417519	
Epoch	18	75.429734706879	
Epoch	19	76.875987768173	
Epoch	20	77.560348153114	
Epoch	21	76.712692975998	
Epoch	22	77.11351108551	
Epoch	23	76.690167665482	
Epoch	24	77.481570959091	
Epoch	25	78.406640529633	
Epoch	26	77.087668299675	
Epoch	27	75.408674240112	
Epoch	28	75.923269748688	
Epoch	29	76.79026222229	
Epoch	30	76.884877324104	
Epoch	31	76.607172966003	
Epoch	32	77.8687312603	
Epoch	33	77.008953928947	
Epoch	34	76.689242124557	
Epoch	35	77.214730381966	
Epoch	36	77.111638069153	
Epoch	37	77.131667256355	
Epoch	38	77.808907985687	
Epoch	39	75.516312718391	
Epoch	40	76.005074858665	
Epoch	41	75.967384338379	
Epoch	42	77.845038414001	
Epoch	43	77.654320597649	
Epoch	44	78.532097458839	
Epoch	45	77.537800431252	
Epoch	46	76.973541975021	
Epoch	47	76.513325214386	
Epoch	48	78.748116731644	
Epoch	49	77.610466361046	
Epoch	50	75.431998729706	
Epoch	51	77.906556844711	
Epoch	52	75.792855024338	
Epoch	53	75.830502510071	
Epoch	54	78.510265111923	
Epoch	55	77.343941569328	
Epoch	56	77.740782856941	
Epoch	57	76.705938458443	
Epoch	58	77.417646169662	
Epoch	59	76.257250666618	
Epoch	60	78.319222569466	
Epoch	61	75.161240696907	
Epoch	62	79.837071061134	
Epoch	63	75.606091380119	
Epoch	64	75.290873169899	
Epoch	65	76.733530640602	
Epoch	66	76.193931221962	
Epoch	67	77.132215261459	
Epoch	68	75.746329069138	
Epoch	69	75.632507562637	
Epoch	70	76.425060033798	
Epoch	71	75.587034106255	
Epoch	72	76.694136381149	
Epoch	73	76.073359131813	
Epoch	74	79.576833724976	
Epoch	75	77.782127022743	
Epoch	76	77.499240994453	
Epoch	77	76.950050711632	
Epoch	78	77.278102040291	
Epoch	79	75.240684747696	
Epoch	80	75.428398251534	
Epoch	81	76.86648607254	
Epoch	82	75.870742082596	
Epoch	83	75.429804563522	
Epoch	84	76.341417431831	
Epoch	85	77.532342791557	
Epoch	86	77.470038294792	
Epoch	87	76.29239487648	
Epoch	88	75.959120631218	
Epoch	89	75.860141277313	
Epoch	90	76.785899400711	
Epoch	91	75.431688666344	
Epoch	92	77.16280400753	
Epoch	93	76.836942315102	
Epoch	94	77.300788164139	
Epoch	95	75.646599531174	
Epoch	96	76.979272484779	
Epoch	97	76.539187788963	
Epoch	98	77.4375	
Epoch	99	77.289854645729	
Epoch	100	76.43655025959	
Epoch	101	75.208914995193	
Epoch	102	84.160665392876	
Epoch	103	76.297501444817	
Epoch	104	76.058222532272	
Epoch	105	76.934353590012	
Epoch	106	76.60821223259	
Epoch	107	76.588689804077	
Epoch	108	76.133333206177	
Epoch	109	78.91308927536	
Epoch	110	76.639412045479	
Epoch	111	76.452732086182	
Epoch	112	77.100322604179	
Epoch	113	78.502110004425	
Epoch	114	78.508088827133	
Epoch	115	78.567308425903	
Epoch	116	76.730215907097	
Epoch	117	77.217166304588	
Epoch	118	77.183780908585	
Epoch	119	76.553411126137	
Epoch	120	76.744305491447	
Epoch	121	76.63772380352	
Epoch	122	81.615186810493	
Epoch	123	84.638103365898	
Epoch	124	76.444088578224	
Epoch	125	80.954693436623	
Epoch	126	76.72500193119	
Epoch	127	75.951230406761	
Epoch	128	82.661522984505	
Epoch	129	77.16651904583	
Epoch	130	77.701323509216	
Epoch	131	77.072075128555	
Epoch	132	76.659874081612	
Epoch	133	75.341235637665	
Epoch	134	76.314778208733	
Epoch	135	77.085185885429	
Epoch	136	76.829572916031	
Epoch	137	77.74809384346	
Epoch	138	75.944167971611	
Epoch	139	79.052294135094	
Epoch	140	76.044429779053	
Epoch	141	77.595022559166	
Epoch	142	77.065266132355	
Epoch	143	76.246205806732	
Epoch	144	76.497354745865	
Epoch	145	76.281718015671	
Epoch	146	76.663407683372	
Epoch	147	77.775625348091	
Epoch	148	76.998298883438	
Epoch	149	76.85709130764	
Epoch	150	76.883056402206	
Epoch	151	76.660289525986	
Epoch	152	76.840441942215	
Epoch	153	75.572427153587	
Epoch	154	75.843386888504	
Epoch	155	76.679884552956	
Epoch	156	76.565985560417	
Epoch	157	76.97604393959	
Epoch	158	76.866089463234	
Epoch	159	75.95949447155	
Epoch	160	77.10172355175	
Epoch	161	77.421207427979	
Epoch	162	76.879557847977	
Epoch	163	75.619975566864	
Epoch	164	76.631461381912	
Epoch	165	77.105136990547	
Epoch	166	76.787448406219	
Epoch	167	76.844922423363	
Epoch	168	75.793732881546	
Epoch	169	76.591573357582	
Epoch	170	76.628970861435	
Epoch	171	75.773280501366	
Epoch	172	75.930579781532	
Epoch	173	76.75020980835	
Epoch	174	77.17043030262	
Epoch	175	76.581227421761	
Epoch	176	76.712648868561	
Epoch	177	77.068029046059	
Epoch	178	75.360936999321	
Epoch	179	75.659433603287	
Epoch	180	77.236364364624	
Epoch	181	75.921008229256	
Epoch	182	76.287648320198	
Epoch	183	77.380530595779	
Epoch	184	75.972248911858	
Epoch	185	76.537896871567	
Epoch	186	76.935030579567	
Epoch	187	75.704617857933	
Epoch	188	76.43293595314	
Epoch	189	78.650629878044	
Epoch	190	79.256197452545	
Epoch	191	75.535290360451	
Epoch	192	75.910057425499	
Epoch	193	76.564897179604	
Epoch	194	77.890303254128	
Epoch	195	77.072243213654	
Epoch	196	77.128353476524	
Epoch	197	77.189761400223	
Epoch	198	76.265180468559	
Epoch	199	76.531762599945	
Epoch	200	77.846293210983	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	15	optimizer:	adagrad	epochs:	200	hidden	10	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	
Accuracy	0.38686262747451	
