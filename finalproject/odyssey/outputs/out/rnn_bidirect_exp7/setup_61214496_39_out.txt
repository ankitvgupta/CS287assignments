[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	50	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	1	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Num features	45	
Test size	 85200
    45
[torch.LongStorage of size 2]

Using cuda	
 1188852
      45
[torch.LongStorage of size 2]

 1188852
[torch.LongStorage of size 1]

     1
 85200
    45
[torch.LongStorage of size 3]

     1
 85200
[torch.LongStorage of size 2]

Data sizes	
  128
 9287
   45
[torch.LongStorage of size 3]

  128
 9287
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> output]
  (1): nn.Transpose
  (2): nn.SplitTable
  (3): nn.Sequencer @ nn.Recursor @ nn.Linear(45 -> 50)
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(50 -> 50)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(50 -> 50)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(100 -> 100)
  (7): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (8): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (9): nn.Sequencer @ nn.Recursor @ nn.Linear(100 -> 10)
  (10): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9287	
Max train index	1	
Num samples	9287	
Epoch	1	229.95067477226	
Epoch	2	167.02354550362	
Epoch	3	167.01824736595	
Epoch	4	167.01807498932	
Epoch	5	167.86323177814	
Epoch	6	167.01807498932	
Epoch	7	167.01807498932	
Epoch	8	167.01807498932	
Epoch	9	167.01807498932	
Epoch	10	167.0180772543	
Epoch	11	167.01807796955	
Epoch	12	167.01807701588	
Epoch	13	167.01807701588	
Epoch	14	167.01807701588	
Epoch	15	167.01807940006	
Epoch	16	167.01800107956	
Epoch	17	167.01807940006	
Epoch	18	167.01807940006	
Epoch	19	167.01807940006	
Epoch	20	167.01807940006	
Epoch	21	167.01807940006	
Epoch	22	167.01807940006	
Epoch	23	167.01807940006	
Epoch	24	167.03926706314	
Epoch	25	167.01807940006	
Epoch	26	167.01807940006	
Epoch	27	167.01807940006	
Epoch	28	167.01807940006	
Epoch	29	167.01807940006	
Epoch	30	167.01776623726	
Epoch	31	167.01808106899	
Epoch	32	167.01807940006	
Epoch	33	167.01807940006	
Epoch	34	167.01807940006	
Epoch	35	167.01807940006	
Epoch	36	167.01807940006	
Epoch	37	167.01807940006	
Epoch	38	167.01807940006	
Epoch	39	167.01807940006	
Epoch	40	167.01807940006	
Epoch	41	167.01807940006	
Epoch	42	167.01807940006	
Epoch	43	167.01807940006	
Epoch	44	167.01807940006	
Epoch	45	167.01807940006	
Epoch	46	167.01807940006	
Epoch	47	167.01807940006	
Epoch	48	167.01807940006	
Epoch	49	167.01807940006	
Epoch	50	167.01807940006	
Epoch	51	167.01808106899	
Epoch	52	167.01808106899	
Epoch	53	167.01808106899	
Epoch	54	167.01890182495	
Epoch	55	167.01808106899	
Epoch	56	167.01808106899	
Epoch	57	167.01808106899	
Epoch	58	167.01808106899	
Epoch	59	167.01808106899	
Epoch	60	167.01794552803	
Epoch	61	167.01807940006	
Epoch	62	167.01807940006	
Epoch	63	167.01807940006	
Epoch	64	167.01807940006	
Epoch	65	167.01807940006	
Epoch	66	167.01807940006	
Epoch	67	167.01807940006	
Epoch	68	167.01807940006	
Epoch	69	167.01807940006	
Epoch	70	167.01807940006	
Epoch	71	167.01807940006	
Epoch	72	167.01807940006	
Epoch	73	167.01807940006	
Epoch	74	167.01807940006	
Epoch	75	167.01807940006	
Epoch	76	167.01807940006	
Epoch	77	167.01807940006	
Epoch	78	167.01807940006	
Epoch	79	167.01807940006	
Epoch	80	167.01807940006	
Epoch	81	167.01807940006	
Epoch	82	167.01807940006	
Epoch	83	167.01807940006	
Epoch	84	167.01807940006	
Epoch	85	167.01807940006	
Epoch	86	167.01807940006	
Epoch	87	167.01807940006	
Epoch	88	167.01807940006	
Epoch	89	167.01807940006	
Epoch	90	167.01807940006	
Epoch	91	167.01807940006	
Epoch	92	167.01807940006	
Epoch	93	167.01807940006	
Epoch	94	167.01807940006	
Epoch	95	167.01807940006	
Epoch	96	167.01807940006	
Epoch	97	167.01807940006	
Epoch	98	167.01807940006	
Epoch	99	167.01807940006	
Epoch	100	167.01807940006	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	50	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	1	
Accuracy	0.30642018779343	
