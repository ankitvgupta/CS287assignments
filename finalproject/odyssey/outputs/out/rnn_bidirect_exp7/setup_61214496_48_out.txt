[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	100	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Num features	45	
Test size	 85200
    45
[torch.LongStorage of size 2]

Using cuda	
 1188852
      45
[torch.LongStorage of size 2]

 1188852
[torch.LongStorage of size 1]

     1
 85200
    45
[torch.LongStorage of size 3]

     1
 85200
[torch.LongStorage of size 2]

Data sizes	
  128
 9287
   45
[torch.LongStorage of size 3]

  128
 9287
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> output]
  (1): nn.Transpose
  (2): nn.SplitTable
  (3): nn.Sequencer @ nn.Recursor @ nn.Linear(45 -> 100)
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (7): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (8): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 100)
  (9): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (10): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (11): nn.Sequencer @ nn.Recursor @ nn.Linear(100 -> 10)
  (12): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9287	
Max train index	1	
Num samples	9287	
Epoch	1	230.30111575127	
Epoch	2	167.62262916565	
Epoch	3	167.61649978161	
Epoch	4	167.61638009548	
Epoch	5	167.61636543274	
Epoch	6	167.61636030674	
Epoch	7	167.61635422707	
Epoch	8	167.61634802818	
Epoch	9	167.61634540558	
Epoch	10	167.61634242535	
Epoch	11	167.6163418293	
Epoch	12	167.61633992195	
Epoch	13	167.61637461185	
Epoch	14	167.61637401581	
Epoch	15	167.61637306213	
Epoch	16	167.61637246609	
Epoch	17	167.61637222767	
Epoch	18	167.6163713932	
Epoch	19	167.6163713932	
Epoch	20	167.61632418633	
Epoch	21	167.61636734009	
Epoch	22	167.61636734009	
Epoch	23	167.61636734009	
Epoch	24	167.61636734009	
Epoch	25	167.61636734009	
Epoch	26	167.61636734009	
Epoch	27	167.61636734009	
Epoch	28	167.61636734009	
Epoch	29	167.61636734009	
Epoch	30	167.61636734009	
Epoch	31	167.61636734009	
Epoch	32	167.61636734009	
Epoch	33	167.61636734009	
Epoch	34	167.61636734009	
Epoch	35	167.61631143093	
Epoch	36	167.61634802818	
Epoch	37	167.61637020111	
Epoch	38	167.61639368534	
Epoch	39	167.61631143093	
Epoch	40	167.6163238287	
Epoch	41	167.61632943153	
Epoch	42	167.61633443832	
Epoch	43	167.61633825302	
Epoch	44	167.61634087563	
Epoch	45	167.61634624004	
Epoch	46	167.61634767056	
Epoch	47	167.61634910107	
Epoch	48	167.61635112762	
Epoch	49	167.61635112762	
Epoch	50	167.61635255814	
Epoch	51	167.61635386944	
Epoch	52	167.61635446548	
Epoch	53	167.61635518074	
Epoch	54	167.61635553837	
Epoch	55	167.61635553837	
Epoch	56	167.61635553837	
Epoch	57	167.61635553837	
Epoch	58	167.61635553837	
Epoch	59	167.61635553837	
Epoch	60	167.61635553837	
Epoch	61	167.61635553837	
Epoch	62	167.61635553837	
Epoch	63	167.61635553837	
Epoch	64	167.61635553837	
Epoch	65	167.61635553837	
Epoch	66	167.61635553837	
Epoch	67	167.61635553837	
Epoch	68	167.61635553837	
Epoch	69	167.61644673347	
Epoch	70	167.61644673347	
Epoch	71	167.61644673347	
Epoch	72	167.61644673347	
Epoch	73	167.61644673347	
Epoch	74	167.61644673347	
Epoch	75	167.61644673347	
Epoch	76	167.61627876759	
Epoch	77	167.61627876759	
Epoch	78	167.61627876759	
Epoch	79	167.61627876759	
Epoch	80	167.61627876759	
Epoch	81	167.61628639698	
Epoch	82	167.61628639698	
Epoch	83	167.61628639698	
Epoch	84	167.61628639698	
Epoch	85	167.61628639698	
Epoch	86	167.61628639698	
Epoch	87	167.61628639698	
Epoch	88	167.61628639698	
Epoch	89	167.61628639698	
Epoch	90	167.61628639698	
Epoch	91	167.61628639698	
Epoch	92	167.61628639698	
Epoch	93	167.61628639698	
Epoch	94	167.61628639698	
Epoch	95	167.61628639698	
Epoch	96	167.61628639698	
Epoch	97	167.61628639698	
Epoch	98	167.61628639698	
Epoch	99	167.61628639698	
Epoch	100	167.61628639698	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	100	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Accuracy	0.30642018779343	
