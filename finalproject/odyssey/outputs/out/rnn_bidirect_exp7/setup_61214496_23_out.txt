[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	100	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	1	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Num features	45	
Test size	 85250
    45
[torch.LongStorage of size 2]

Using cuda	
 1188852
      45
[torch.LongStorage of size 2]

 1188852
[torch.LongStorage of size 1]

     1
 85250
    45
[torch.LongStorage of size 3]

     1
 85250
[torch.LongStorage of size 2]

Data sizes	
  128
 9287
   45
[torch.LongStorage of size 3]

  128
 9287
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> output]
  (1): nn.Transpose
  (2): nn.SplitTable
  (3): nn.Sequencer @ nn.Recursor @ nn.Linear(45 -> 100)
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 100)
  (7): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (8): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (9): nn.Sequencer @ nn.Recursor @ nn.Linear(100 -> 10)
  (10): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9287	
Max train index	1	
Num samples	9287	
Epoch	1	115.56120347977	
Epoch	2	82.988145232201	
Epoch	3	82.981418013573	
Epoch	4	82.98141181469	
Epoch	5	82.981433033943	
Epoch	6	82.98142683506	
Epoch	7	82.981424331665	
Epoch	8	82.98142683506	
Epoch	9	82.981425285339	
Epoch	10	82.981418013573	
Epoch	11	82.981426119804	
Epoch	12	82.981424450874	
Epoch	13	82.981431722641	
Epoch	14	82.98143017292	
Epoch	15	82.981427550316	
Epoch	16	82.98142683506	
Epoch	17	82.981436491013	
Epoch	18	82.981435060501	
Epoch	19	82.981435060501	
Epoch	20	82.981434226036	
Epoch	21	82.981433272362	
Epoch	22	82.981431603432	
Epoch	23	82.981431126595	
Epoch	24	82.981430649757	
Epoch	25	82.981429457664	
Epoch	26	82.981429457664	
Epoch	27	82.981429100037	
Epoch	28	82.981428623199	
Epoch	29	82.98142850399	
Epoch	30	82.981427073479	
Epoch	31	82.981426954269	
Epoch	32	82.981426954269	
Epoch	33	82.981426954269	
Epoch	34	82.981426596642	
Epoch	35	82.981426119804	
Epoch	36	82.981425881386	
Epoch	37	82.981426119804	
Epoch	38	82.981425881386	
Epoch	39	82.981425881386	
Epoch	40	82.981425881386	
Epoch	41	82.981425881386	
Epoch	42	82.981425881386	
Epoch	43	82.981425642967	
Epoch	44	82.981425642967	
Epoch	45	82.981425642967	
Epoch	46	82.981425642967	
Epoch	47	82.981425642967	
Epoch	48	82.981425642967	
Epoch	49	82.981425642967	
Epoch	50	82.981425642967	
Epoch	51	82.981425642967	
Epoch	52	82.981425642967	
Epoch	53	82.981425642967	
Epoch	54	82.981425642967	
Epoch	55	82.981425642967	
Epoch	56	82.982223629951	
Epoch	57	82.981425642967	
Epoch	58	82.981425642967	
Epoch	59	82.981406450272	
Epoch	60	82.981425642967	
Epoch	61	82.981452822685	
Epoch	62	82.981425642967	
Epoch	63	82.981406450272	
Epoch	64	82.981425642967	
Epoch	65	82.981452822685	
Epoch	66	82.981425642967	
Epoch	67	82.981442809105	
Epoch	68	82.981418251991	
Epoch	69	82.981442809105	
Epoch	70	82.981418251991	
Epoch	71	82.981436133385	
Epoch	72	82.981410741806	
Epoch	73	82.981423735619	
Epoch	74	82.981438159943	
Epoch	75	82.981451630592	
Epoch	76	82.981408119202	
Epoch	77	82.981413602829	
Epoch	78	82.981418609619	
Epoch	79	82.428178548813	
Epoch	80	82.981439709663	
Epoch	81	82.981443285942	
Epoch	82	82.981396794319	
Epoch	83	82.98140001297	
Epoch	84	82.981401205063	
Epoch	85	82.981402873993	
Epoch	86	82.981403112411	
Epoch	87	82.981404662132	
Epoch	88	82.981406450272	
Epoch	89	82.981407880783	
Epoch	90	82.981409192085	
Epoch	91	82.981409430504	
Epoch	92	82.981409549713	
Epoch	93	82.981409668922	
Epoch	94	82.981409907341	
Epoch	95	82.981409907341	
Epoch	96	82.981410384178	
Epoch	97	82.981410741806	
Epoch	98	82.981411099434	
Epoch	99	82.981411457062	
Epoch	100	82.98141169548	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/EPRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	100	optimizer:	adagrad	epochs:	100	hidden	100	eta:	0.1	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	1	
Accuracy	0.30624046920821	
