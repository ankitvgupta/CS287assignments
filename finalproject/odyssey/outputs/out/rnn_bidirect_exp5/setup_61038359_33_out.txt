[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/FILT_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	200	embedding_size	100	optimizer:	sgd	epochs:	30	hidden	200	eta:	0.2	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83200
[torch.LongStorage of size 2]

Using cuda	
 26500986
        1
[torch.LongStorage of size 2]

    128
 207038
[torch.LongStorage of size 2]

    128
 207038
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> output]
  (1): nn.LookupTable
  (2): nn.Transpose
  (3): nn.SplitTable
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (7): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (8): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 200)
  (9): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (10): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (11): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 10)
  (12): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	207038	
Max train index	26	
Num samples	207038	
Epoch	1	458.9339761734	
Epoch	2	263.00189304352	
Epoch	3	247.47944021225	
Epoch	4	240.18539988995	
Epoch	5	234.7874841094	
Epoch	6	231.34756338596	
Epoch	7	227.33323162794	
Epoch	8	226.05202627182	
Epoch	9	223.03122729063	
Epoch	10	220.94805926085	
Epoch	11	218.37871444225	
Epoch	12	215.66296321154	
Epoch	13	216.8207719326	
Epoch	14	213.04825049639	
Epoch	15	211.99515795708	
Epoch	16	213.3948662281	
Epoch	17	208.68542003632	
Epoch	18	210.3752194047	
Epoch	19	206.90255612135	
Epoch	20	208.09813261032	
Epoch	21	204.40369552374	
Epoch	22	203.27300667763	
Epoch	23	203.52551198006	
Epoch	24	204.75446468592	
Epoch	25	204.50616085529	
Epoch	26	201.93726968765	
Epoch	27	204.65490084887	
Epoch	28	202.37443721294	
Epoch	29	204.29497146606	
Epoch	30	202.08892285824	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/FILT_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	200	embedding_size	100	optimizer:	sgd	epochs:	30	hidden	200	eta:	0.2	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Accuracy	0.53793269230769	
