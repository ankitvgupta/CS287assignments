[?1034hUsing cuda	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/FILT_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	100	optimizer:	sgd	epochs:	30	hidden	200	eta:	0.05	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83300
[torch.LongStorage of size 2]

Using cuda	
 26500986
        1
[torch.LongStorage of size 2]

    128
 207038
[torch.LongStorage of size 2]

    128
 207038
[torch.LongStorage of size 2]

Converted LSTM to CUDA	
Converted crit to CUDA	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> output]
  (1): nn.LookupTable
  (2): nn.Transpose
  (3): nn.SplitTable
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (6): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(200 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (7): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (8): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 200)
  (9): nn.Sequencer @ nn.Recursor @ nn.ReLU
  (10): nn.Sequencer @ nn.Recursor @ nn.Dropout(0.5, busy)
  (11): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 10)
  (12): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	207038	
Max train index	26	
Num samples	207038	
Epoch	1	230.91962313652	
Epoch	2	127.0250235796	
Epoch	3	119.04259395599	
Epoch	4	116.3368255496	
Epoch	5	114.29391139746	
Epoch	6	112.45100021362	
Epoch	7	111.28576773405	
Epoch	8	110.63159483671	
Epoch	9	109.91164064407	
Epoch	10	108.60020834208	
Epoch	11	107.89193350077	
Epoch	12	106.6020629406	
Epoch	13	106.03756433725	
Epoch	14	106.05313783884	
Epoch	15	105.81029587984	
Epoch	16	104.32858276367	
Epoch	17	104.69737678766	
Epoch	18	104.39336019754	
Epoch	19	104.50783365965	
Epoch	20	105.09084767103	
Epoch	21	104.59058618546	
Epoch	22	103.8245241642	
Epoch	23	103.03248167038	
Epoch	24	104.69446730614	
Epoch	25	103.95831739902	
Epoch	26	104.0628195405	
Epoch	27	103.16762155294	
Epoch	28	103.74429816008	
Epoch	29	103.06687515974	
Epoch	30	103.01152253151	
Starting the testing	
datafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/FILT_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	100	embedding_size	100	optimizer:	sgd	epochs:	30	hidden	200	eta:	0.05	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	num_bidir_layers	2	
Accuracy	0.5334093637455	
