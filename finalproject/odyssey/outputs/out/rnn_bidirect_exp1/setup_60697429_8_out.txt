[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	100	optimizer:	sgd	epochs:	50	hidden	200	eta:	0.05	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83350
[torch.LongStorage of size 2]

 1183318
       1
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> output]
  (1): nn.LookupTable
  (2): nn.Transpose
  (3): nn.SplitTable
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 200)
  (6): nn.Sequencer @ nn.Recursor @ nn.Tanh
  (7): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 10)
  (8): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9244	
Max train index	23	
Epoch	1	116.27833160398	
Epoch	2	70.322346405441	
Epoch	3	67.060949099949	
Epoch	4	67.171148255272	
Epoch	5	66.709161051835	
Epoch	6	66.240168115311	
Epoch	7	65.821166687069	
Epoch	8	64.197633092087	
Epoch	9	63.578146758543	
Epoch	10	63.105250171935	
Epoch	11	62.669349078225	
Epoch	12	62.259483678164	
Epoch	13	61.89973091175	
Epoch	14	61.580204024621	
Epoch	15	62.142520132555	
Epoch	16	61.874196903785	
Epoch	17	61.558111502341	
Epoch	18	61.17640269813	
Epoch	19	60.641215614314	
Epoch	20	60.093012655461	
Epoch	21	59.993461368501	
Epoch	22	59.81102529133	
Epoch	23	59.668520434128	
Epoch	24	59.525394639955	
Epoch	25	59.34250937318	
Epoch	26	59.250320869588	
Epoch	27	59.172623601842	
Epoch	28	59.100053557227	
Epoch	29	59.027157440009	
Epoch	30	58.955024852006	
Epoch	31	58.881333145193	
Epoch	32	58.798857653401	
Epoch	33	58.723615143135	
Epoch	34	58.650328408684	
Epoch	35	58.577687255092	
Epoch	36	58.502560065208	
Epoch	37	58.410233246747	
Epoch	38	58.312202381641	
Epoch	39	58.245034662961	
Epoch	40	58.17561386532	
