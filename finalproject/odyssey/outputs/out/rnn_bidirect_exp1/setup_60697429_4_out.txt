[?1034hdatafile:	/n/home09/ankitgupta/CS287/CS287assignments/finalproject/PRINC_CB513_1.hdf5	classifier:	rnn	b:	128	alpha:	1	sequence_length:	50	embedding_size	100	optimizer:	sgd	epochs:	50	hidden	100	eta:	0.05	rnn_unit1	lstm	rnn_unit2	lstm	dropout	0.5	
Num classes:	10	
Vocab size:	37	
Start class:	1	
Test size	     1
 83350
[torch.LongStorage of size 2]

 1183318
       1
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

  128
 9244
[torch.LongStorage of size 2]

nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> output]
  (1): nn.LookupTable
  (2): nn.Transpose
  (3): nn.SplitTable
  (4): nn.BiSequencer @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> output]
    (1): nn.ConcatTable {
      input
        |`-> (1): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> (3) -> output]
        |      (1): nn.ReverseTable
        |      (2): nn.Sequencer @ nn.FastLSTM(100 -> 100)
        |      (3): nn.ReverseTable
        |    }
         ... -> output
    }
    (2): nn.ZipTable
    (3): nn.Sequencer @ nn.Recursor @ nn.JoinTable
  }
  (5): nn.Sequencer @ nn.Recursor @ nn.Linear(200 -> 100)
  (6): nn.Sequencer @ nn.Recursor @ nn.Tanh
  (7): nn.Sequencer @ nn.Recursor @ nn.Linear(100 -> 10)
  (8): nn.Sequencer @ nn.Recursor @ nn.LogSoftMax
}
Input size	9244	
Max train index	23	
Epoch	1	115.6973095753	
Epoch	2	70.535916161982	
Epoch	3	67.826840573615	
Epoch	4	67.632005882941	
Epoch	5	66.912158606911	
Epoch	6	65.158452411784	
Epoch	7	64.815486372004	
Epoch	8	64.503303067608	
Epoch	9	65.224546964862	
Epoch	10	64.694318136416	
Epoch	11	62.957702510098	
Epoch	12	62.325803219993	
Epoch	13	61.859472036679	
Epoch	14	61.498933773313	
Epoch	15	62.112044763055	
Epoch	16	61.820110585979	
Epoch	17	61.530325907226	
Epoch	18	61.190948386791	
Epoch	19	60.574856881846	
Epoch	20	59.678627664634	
Epoch	21	59.820987713389	
Epoch	22	59.557787032308	
Epoch	23	59.279273012794	
Epoch	24	59.213981691285	
Epoch	25	59.024506394059	
Epoch	26	58.903188129182	
Epoch	27	58.825171109662	
Epoch	28	58.758386144953	
Epoch	29	58.701861352815	
Epoch	30	58.633513468434	
Epoch	31	58.565425894825	
Epoch	32	58.505739844253	
Epoch	33	58.439586677042	
Epoch	34	58.369010833312	
Epoch	35	58.29761049239	
Epoch	36	58.219939484221	
Epoch	37	58.142594609582	
Epoch	38	58.070118148048	
Epoch	39	58.004044507403	
Epoch	40	57.9314729293	
Epoch	41	57.848604564324	
Epoch	42	57.763400280502	
Epoch	43	57.673369692488	
Epoch	44	57.577591676288	
Epoch	45	57.471393862068	
Epoch	46	57.390745008478	
Epoch	47	57.303557244683	
