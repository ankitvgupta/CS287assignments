[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nce	Alpha:	0.001	Eta:	0.0001	Lambda:	1	Minibatch size:	512	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	100	Embedding size:	50	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Making NCE neural network model	
 929589
      5
[torch.LongStorage of size 2]

Epoch	1	L1 norm of model params:	399029.0615373	LookupParams:	797011.94444327	Biasparams:	7944.8555652095	
Accuracy, CrossEntropy, Perplexity:	0.025519287833828	11.00300189967	60054.147926547	
Epoch	2	L1 norm of model params:	399025.24075476	LookupParams:	797011.78515617	Biasparams:	7944.8331071055	
Accuracy, CrossEntropy, Perplexity:	0.016023738872404	11.738577181317	125313.91413875	
Epoch	3	L1 norm of model params:	399022.02942892	LookupParams:	797011.65898207	Biasparams:	7944.8174835378	
Accuracy, CrossEntropy, Perplexity:	0.015430267062315	12.035804891528	168687.79044096	
Epoch	4	L1 norm of model params:	399019.04609752	LookupParams:	797011.5472962	Biasparams:	7944.8044307204	
Accuracy, CrossEntropy, Perplexity:	0.013649851632047	12.22996378801	204835.76445111	
Epoch	5	L1 norm of model params:	399016.25291079	LookupParams:	797011.44494097	Biasparams:	7944.7928472625	
Accuracy, CrossEntropy, Perplexity:	0.012462908011869	12.37239234299	236190.1176565	
Epoch	6	L1 norm of model params:	399013.60978799	LookupParams:	797011.34933455	Biasparams:	7944.7822595527	
Accuracy, CrossEntropy, Perplexity:	0.012166172106825	12.484970663262	264334.50996648	
Epoch	7	L1 norm of model params:	399011.06836171	LookupParams:	797011.25899076	Biasparams:	7944.7724108944	
Accuracy, CrossEntropy, Perplexity:	0.01186943620178	12.577093096514	289842.54218186	
Epoch	8	L1 norm of model params:	399008.60374641	LookupParams:	797011.17293572	Biasparams:	7944.7631434808	
Accuracy, CrossEntropy, Perplexity:	0.011572700296736	12.653459960205	312844.00546925	
Epoch	9	L1 norm of model params:	399006.19366578	LookupParams:	797011.09049537	Biasparams:	7944.7543488528	
Accuracy, CrossEntropy, Perplexity:	0.010385756676558	12.717419767083	333507.2112634	
