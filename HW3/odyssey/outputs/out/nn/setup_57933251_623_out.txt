[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.016913946587537	3.9660418011958	
L1 norm of params:	415989.2737407	
Loss: 	9.3034681686701	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.55697329376855	2.0755934297048	
L1 norm of params:	641251.8594935	
Loss: 	7.6059171263426	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.56261127596439	2.0984857056137	
L1 norm of params:	601974.96869685	
Loss: 	8.386823630258	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.56557863501484	2.4513275416391	
L1 norm of params:	826669.71123019	
Loss: 	10.246541083001	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56379821958457	2.6042446419961	
L1 norm of params:	1006648.1963677	
Loss: 	10.823913450662	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56439169139466	2.8898056789912	
L1 norm of params:	1161998.0326796	
Loss: 	11.789520414296	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56498516320475	3.1818644829153	
L1 norm of params:	1321062.9355755	
Loss: 	12.740192799324	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56439169139466	3.4240970948773	
L1 norm of params:	1485597.7296066	
Loss: 	13.467824290299	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.56587537091988	3.5716208235059	
L1 norm of params:	1671207.6456981	
Loss: 	13.897188492971	
