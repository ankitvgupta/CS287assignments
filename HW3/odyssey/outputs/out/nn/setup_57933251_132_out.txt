[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.024035608308605	3.954062006892	
L1 norm of params:	834535.82025161	
Loss: 	9.2210798344861	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.16231454005935	3.6621922576533	
L1 norm of params:	834535.69085757	
Loss: 	9.0289421003987	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.2919881305638	3.2673965609003	
L1 norm of params:	834550.50761752	
Loss: 	8.6702089586733	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.38308605341246	2.9039959103539	
L1 norm of params:	834558.13163258	
Loss: 	8.2383113888518	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.43649851632047	2.6460998833271	
L1 norm of params:	834562.63475704	
Loss: 	7.8797980060685	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.46973293768546	2.4954907874023	
L1 norm of params:	834567.56259235	
Loss: 	7.7247838863224	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.48872403560831	2.3931970244228	
L1 norm of params:	834575.42358147	
Loss: 	7.6558243305182	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.49940652818991	2.3149381949177	
L1 norm of params:	834585.4458044	
Loss: 	7.6057589809513	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.5106824925816	2.2533601020475	
L1 norm of params:	834596.6145594	
Loss: 	7.5686792692344	
