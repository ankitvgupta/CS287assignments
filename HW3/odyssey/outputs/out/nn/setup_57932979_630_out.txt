[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.19228486646884	3.9378798707913	
L1 norm of params:	86224.790939343	
Loss: 	6.8753728278261	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.2973293768546	7.4326829841487	
L1 norm of params:	110626.33938154	
Loss: 	4.0819107138232	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.30445103857567	7.1879054792404	
L1 norm of params:	123875.32188041	
Loss: 	4.002071368417	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.30415430267062	8.1824795286473	
L1 norm of params:	158945.32569708	
Loss: 	4.7045723757631	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.30771513353116	8.7416635142449	
L1 norm of params:	204543.85888044	
Loss: 	5.2202182293517	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.313353115727	9.3193170885363	
L1 norm of params:	240300.88139901	
Loss: 	5.7429690830714	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.313353115727	9.8222327401509	
L1 norm of params:	272170.18389285	
Loss: 	6.1824173252451	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.31424332344214	10.177510080898	
L1 norm of params:	309705.91376282	
Loss: 	6.4468559361986	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.32195845697329	10.361751986299	
L1 norm of params:	353957.27768048	
Loss: 	6.5932870623763	
