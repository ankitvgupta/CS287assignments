[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.016617210682493	3.9731180506344	
L1 norm of params:	435108.53814947	
Loss: 	9.2835949765763	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.03946587537092	3.913468133344	
L1 norm of params:	435106.50119373	
Loss: 	9.2210687991663	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.067952522255193	3.8583002221342	
L1 norm of params:	435105.38771611	
Loss: 	9.161208126038	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.091691394658754	3.8011433348328	
L1 norm of params:	435104.93616618	
Loss: 	9.0986874254498	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.12195845697329	3.740418967477	
L1 norm of params:	435104.96076777	
Loss: 	9.0317807704864	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.15519287833828	3.6724260942348	
L1 norm of params:	435105.6383793	
Loss: 	8.9554143381275	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.19554896142433	3.5961868106693	
L1 norm of params:	435106.9633808	
Loss: 	8.8670976628345	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.23442136498516	3.5121936104476	
L1 norm of params:	435108.88523669	
Loss: 	8.7671884120444	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.26379821958457	3.4218624009092	
L1 norm of params:	435111.35189075	
Loss: 	8.6580093322916	
