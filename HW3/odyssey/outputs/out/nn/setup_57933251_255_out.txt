[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	10	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.017507418397626	4.014852731855	
L1 norm of params:	814725.03421589	
Loss: 	9.312027349751	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.019584569732938	3.9809845835861	
L1 norm of params:	814723.2167617	
Loss: 	9.2804097623469	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.023442136498516	3.9501274063784	
L1 norm of params:	814721.71305567	
Loss: 	9.2523069416996	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.035014836795252	3.9217623969117	
L1 norm of params:	814720.46474526	
Loss: 	9.2267987267024	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.054302670623145	3.8948340552775	
L1 norm of params:	814719.39856889	
Loss: 	9.2016020744307	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.066765578635015	3.8680786455579	
L1 norm of params:	814718.50574907	
Loss: 	9.1753356873089	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.086943620178042	3.8406830111453	
L1 norm of params:	814717.87814056	
Loss: 	9.148007581731	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.10623145400593	3.8121353634345	
L1 norm of params:	814717.50545322	
Loss: 	9.1190906096579	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.12166172106825	3.7820960750075	
L1 norm of params:	814717.30204485	
Loss: 	9.0884769660396	
