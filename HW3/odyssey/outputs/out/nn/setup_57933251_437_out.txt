[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.018100890207715	3.9753697462129	
L1 norm of params:	435231.79340135	
Loss: 	9.3953790163262	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.46053412462908	2.4935223929868	
L1 norm of params:	435273.43989708	
Loss: 	8.9004309873187	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.52581602373887	2.165391078112	
L1 norm of params:	435295.73212555	
Loss: 	8.9071464424963	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.54391691394659	2.0385108098909	
L1 norm of params:	435322.18691667	
Loss: 	9.0168113339937	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.55222551928783	1.9641813007462	
L1 norm of params:	435354.69469235	
Loss: 	9.1108001355316	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56172106824926	1.9128026441027	
L1 norm of params:	435391.53472097	
Loss: 	9.1862766780935	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56765578635015	1.8739239882091	
L1 norm of params:	435430.5890035	
Loss: 	9.248324298447	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.57062314540059	1.8431935018258	
L1 norm of params:	435471.32882562	
Loss: 	9.2997045502686	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.57329376854599	1.8179508063535	
L1 norm of params:	435512.92598916	
Loss: 	9.3403944426393	
