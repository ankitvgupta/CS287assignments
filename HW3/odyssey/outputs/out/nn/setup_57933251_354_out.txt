[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.017210682492582	4.0137436054158	
L1 norm of params:	815806.97716997	
Loss: 	9.3194089859547	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.5593471810089	2.0894215806751	
L1 norm of params:	1160188.960167	
Loss: 	7.5026486324576	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.56320474777448	2.0713399595984	
L1 norm of params:	1000201.532731	
Loss: 	8.2221369901492	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.5646884272997	2.4915436639279	
L1 norm of params:	1215435.9308823	
Loss: 	10.680322108146	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56498516320475	2.6461267457955	
L1 norm of params:	1333423.1874915	
Loss: 	11.131288281348	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56528189910979	2.9217332337163	
L1 norm of params:	1442605.8715448	
Loss: 	12.03885556763	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56557863501484	3.2092939230656	
L1 norm of params:	1536107.5149835	
Loss: 	12.950967345372	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56557863501484	3.4320692451512	
L1 norm of params:	1656321.753953	
Loss: 	13.592285240669	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.56646884272997	3.5579558440081	
L1 norm of params:	1826038.1217784	
Loss: 	13.995273217296	
