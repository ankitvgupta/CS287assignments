[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.16557863501484	3.8515027238343	
L1 norm of params:	44004.886360624	
Loss: 	6.9784397455293	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.29436201780415	6.7983824370104	
L1 norm of params:	68724.225546068	
Loss: 	3.8328817666453	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.29376854599407	7.7857808838137	
L1 norm of params:	71579.604867649	
Loss: 	4.3787413810614	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.29910979228487	8.3030571890688	
L1 norm of params:	97075.03795233	
Loss: 	4.7999970037125	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.30356083086053	8.8688392782609	
L1 norm of params:	124978.70976311	
Loss: 	5.2829023270714	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.30830860534125	9.4379636278856	
L1 norm of params:	150497.24991853	
Loss: 	5.8005531794249	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.31008902077151	9.9340744862802	
L1 norm of params:	175912.58824359	
Loss: 	6.23467608827	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.30919881305638	10.272920912264	
L1 norm of params:	204982.78843498	
Loss: 	6.4828147243664	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.30919881305638	10.481037087191	
L1 norm of params:	239591.17308781	
Loss: 	6.6393661574263	
