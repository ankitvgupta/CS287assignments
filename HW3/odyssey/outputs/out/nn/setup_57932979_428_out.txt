[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.21543026706231	3.8963237676748	
L1 norm of params:	43673.061933598	
Loss: 	6.9206541650509	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.29970326409496	6.3140139769035	
L1 norm of params:	56148.861670648	
Loss: 	4.192891715503	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.32848664688427	6.1871235784688	
L1 norm of params:	63080.674569828	
Loss: 	4.1245220670735	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.33234421364985	6.1315316321913	
L1 norm of params:	66184.957820958	
Loss: 	4.1098638004823	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.3406528189911	6.1576580055876	
L1 norm of params:	70322.333011949	
Loss: 	4.0731262270746	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.33857566765579	6.1575135113727	
L1 norm of params:	73688.997125227	
Loss: 	4.0440867436854	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.34510385756677	6.1375822668981	
L1 norm of params:	77389.874922383	
Loss: 	4.0402434799971	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.33976261127596	6.122379777753	
L1 norm of params:	79642.379999786	
Loss: 	4.0459813943827	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.34985163204748	6.144423995054	
L1 norm of params:	80039.97737361	
Loss: 	4.0137755233728	
