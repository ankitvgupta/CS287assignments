[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.016913946587537	3.9544635345001	
L1 norm of params:	834810.88428946	
Loss: 	9.2479109154825	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.20712166172107	3.5799583309715	
L1 norm of params:	834809.94965556	
Loss: 	8.9371956786891	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.32818991097923	3.1173606192655	
L1 norm of params:	834828.25520498	
Loss: 	8.4628356145244	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.41275964391691	2.7886062242677	
L1 norm of params:	834838.94580344	
Loss: 	8.0774267806956	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.45697329376855	2.5770018991931	
L1 norm of params:	834841.29567669	
Loss: 	7.8361971743763	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.4813056379822	2.4373047025367	
L1 norm of params:	834842.55993022	
Loss: 	7.6947832822266	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.49673590504451	2.3395835290946	
L1 norm of params:	834847.08943696	
Loss: 	7.6105576685821	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.5080118694362	2.2677075867064	
L1 norm of params:	834854.25245468	
Loss: 	7.5614940257729	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.5160237388724	2.2122991818391	
L1 norm of params:	834863.41631954	
Loss: 	7.5318605792777	
