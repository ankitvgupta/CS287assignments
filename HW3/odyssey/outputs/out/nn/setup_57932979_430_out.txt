[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.16083086053412	3.9079513697164	
L1 norm of params:	25424.572981527	
Loss: 	6.9885452421625	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.30148367952522	6.3979151928871	
L1 norm of params:	47041.57093307	
Loss: 	4.1687077623158	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.3160237388724	6.2975376144106	
L1 norm of params:	52474.516983841	
Loss: 	4.1239148212805	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.33145400593472	6.214757217588	
L1 norm of params:	56604.516498601	
Loss: 	4.0729341802911	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.33323442136499	6.2083337272908	
L1 norm of params:	58793.393859931	
Loss: 	4.0729534932801	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.33976261127596	6.1916317011018	
L1 norm of params:	59884.485091252	
Loss: 	4.065593035942	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.33857566765579	6.1972360168624	
L1 norm of params:	66096.190052252	
Loss: 	4.0551655960261	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.33590504451039	6.1827576890716	
L1 norm of params:	67636.914372358	
Loss: 	4.0681350645763	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.33827893175074	6.1680626114302	
L1 norm of params:	67854.439979222	
Loss: 	4.0510329748848	
