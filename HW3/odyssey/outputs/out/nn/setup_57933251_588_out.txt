[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.017210682492582	4.020385849785	
L1 norm of params:	815730.19131704	
Loss: 	9.3413439954848	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.55578635014837	1.9029270093286	
L1 norm of params:	881426.02257158	
Loss: 	6.9244076306632	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.56973293768546	1.8134967595782	
L1 norm of params:	921649.19683271	
Loss: 	6.7174531141974	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.57477744807122	1.7653388413355	
L1 norm of params:	951566.12524554	
Loss: 	6.5960926442278	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.58160237388724	1.7460656290033	
L1 norm of params:	946370.6078972	
Loss: 	6.5482209340353	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.58249258160237	1.7461738338814	
L1 norm of params:	923150.62009379	
Loss: 	6.546239984492	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.58041543026706	1.863780841296	
L1 norm of params:	925363.14062477	
Loss: 	6.7376776154005	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.59109792284866	1.7340639978502	
L1 norm of params:	938599.00018423	
Loss: 	6.5861702310451	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.59139465875371	1.7209473794632	
L1 norm of params:	967008.72516306	
Loss: 	6.4952094969486	
