[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.18041543026706	3.8051630010817	
L1 norm of params:	23841.626363192	
Loss: 	6.9862672519821	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.29020771513353	6.7965745277144	
L1 norm of params:	47189.774826866	
Loss: 	3.761238048334	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.27744807121662	7.9757805503832	
L1 norm of params:	52514.725411863	
Loss: 	4.4404717819275	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.29436201780415	8.3478899153729	
L1 norm of params:	76962.421007282	
Loss: 	4.8716940891103	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.29910979228487	8.9069533822953	
L1 norm of params:	104850.62875263	
Loss: 	5.3328661532077	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.30089020771513	9.4687165573519	
L1 norm of params:	130924.03857565	
Loss: 	5.8219100402994	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.30178041543027	9.9669837011409	
L1 norm of params:	156154.77736842	
Loss: 	6.2540589856342	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.30593471810089	10.292809778602	
L1 norm of params:	182521.72465012	
Loss: 	6.5278619024174	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.3053412462908	10.510252804607	
L1 norm of params:	210819.97208352	
Loss: 	6.6872235921133	
