[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.016913946587537	3.9513569168388	
L1 norm of params:	235786.50359589	
Loss: 	9.2459294791852	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56557863501484	2.0378467465767	
L1 norm of params:	725467.67708399	
Loss: 	7.5558762013373	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.56439169139466	2.059305175279	
L1 norm of params:	487881.28333544	
Loss: 	8.0461021054446	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.56439169139466	2.4991862756283	
L1 norm of params:	840692.25343574	
Loss: 	10.352242675215	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56557863501484	2.6344302393898	
L1 norm of params:	1112281.3282276	
Loss: 	11.363024922074	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56824925816024	2.9202655858764	
L1 norm of params:	1292886.975685	
Loss: 	12.069977953865	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.5673590504451	3.206463941718	
L1 norm of params:	1521625.4799116	
Loss: 	12.940240500258	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56943620178042	3.42281411719	
L1 norm of params:	1780219.0590206	
Loss: 	13.578303578944	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.57032640949555	3.5393966516632	
L1 norm of params:	2133997.3746202	
Loss: 	13.960262881888	
