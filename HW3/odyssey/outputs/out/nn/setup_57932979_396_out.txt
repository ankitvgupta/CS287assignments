[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.18249258160237	4.0279357003647	
L1 norm of params:	85298.851678205	
Loss: 	6.6542572298584	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.27507418397626	9.5201410551722	
L1 norm of params:	169084.47563268	
Loss: 	2.2591115015786	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.28427299703264	11.816563589886	
L1 norm of params:	255950.40934366	
Loss: 	2.7923980692246	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.28991097922849	12.469902751384	
L1 norm of params:	458690.65913576	
Loss: 	3.0661225485512	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.29347181008902	12.743215031943	
L1 norm of params:	615911.71541027	
Loss: 	3.1010699780577	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.29020771513353	12.839224335642	
L1 norm of params:	794349.75882437	
Loss: 	3.178245856192	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.29287833827893	12.907331753558	
L1 norm of params:	1013656.476349	
Loss: 	3.1381828983395	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.29347181008902	12.953479803139	
L1 norm of params:	1162543.4075125	
Loss: 	3.1004502536856	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.29525222551929	13.00821419283	
L1 norm of params:	1264463.7980811	
Loss: 	3.1659141977131	
