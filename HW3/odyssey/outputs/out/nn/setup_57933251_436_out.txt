[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.017804154302671	3.9676932849173	
L1 norm of params:	235645.65561626	
Loss: 	9.245331675535	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.46023738872404	2.5266345834555	
L1 norm of params:	235682.83458637	
Loss: 	8.8965030631501	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.51899109792285	2.2012094410474	
L1 norm of params:	235705.6978378	
Loss: 	8.9064457729036	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.54005934718101	2.0699811022058	
L1 norm of params:	235730.35325522	
Loss: 	8.9966177104679	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.55163204747774	1.9888509226911	
L1 norm of params:	235759.89488141	
Loss: 	9.0891083011139	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56083086053412	1.9324961571681	
L1 norm of params:	235791.48401711	
Loss: 	9.16932373946	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56617210682493	1.8902944196846	
L1 norm of params:	235824.78942524	
Loss: 	9.2389180779173	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56913946587537	1.8574853583112	
L1 norm of params:	235859.25251101	
Loss: 	9.3025064356353	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.57359050445104	1.8311663309373	
L1 norm of params:	235894.2929595	
Loss: 	9.3570769061307	
