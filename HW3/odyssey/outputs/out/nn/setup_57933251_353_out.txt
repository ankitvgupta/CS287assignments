[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.017507418397626	4.0011755651465	
L1 norm of params:	415835.57867684	
Loss: 	9.2592303046518	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56587537091988	2.0755593162336	
L1 norm of params:	654324.88001845	
Loss: 	7.5868034989521	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.56290801186944	2.0999758997504	
L1 norm of params:	603727.34598105	
Loss: 	8.4496468185684	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.56587537091988	2.5053560732349	
L1 norm of params:	785194.28407386	
Loss: 	10.547342837986	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56557863501484	2.6583226480654	
L1 norm of params:	894537.95958297	
Loss: 	11.205223769057	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56676557863501	2.9390623775578	
L1 norm of params:	1021747.3270073	
Loss: 	12.14462385574	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56498516320475	3.2246693562791	
L1 norm of params:	1158681.5926997	
Loss: 	13.052175778414	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56557863501484	3.4425872096004	
L1 norm of params:	1328289.1956887	
Loss: 	13.699025450194	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.56706231454006	3.5647147585088	
L1 norm of params:	1556843.6722151	
Loss: 	14.069643519065	
