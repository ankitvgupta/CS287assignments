[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.016023738872404	3.9656157964766	
L1 norm of params:	235370.3011497	
Loss: 	9.2904557180872	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.58694362017804	1.7486494571003	
L1 norm of params:	484540.43086592	
Loss: 	6.5716512049035	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.58991097922849	1.7207823145823	
L1 norm of params:	562171.83432367	
Loss: 	6.5215712599131	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.5919881305638	1.7142600513154	
L1 norm of params:	588749.59173481	
Loss: 	6.5005142195809	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.5946587537092	1.7038508222069	
L1 norm of params:	562063.8046607	
Loss: 	6.4545891871177	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.58902077151335	1.705196066186	
L1 norm of params:	584207.18847877	
Loss: 	6.4340360754297	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.59080118694362	1.7072721573076	
L1 norm of params:	642822.0415929	
Loss: 	6.4331675636285	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.59376854599407	1.7053186290186	
L1 norm of params:	664336.12039455	
Loss: 	6.4140239790965	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.59495548961424	1.6930574912039	
L1 norm of params:	614350.95109542	
Loss: 	6.4122452342747	
