[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.15608308605341	3.8380749619184	
L1 norm of params:	84038.489650756	
Loss: 	7.0099374318585	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.24451038575668	6.163752757816	
L1 norm of params:	84040.814008153	
Loss: 	5.8254720869472	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.24510385756677	7.1800846218449	
L1 norm of params:	84044.226840434	
Loss: 	5.3461877315436	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.24391691394659	7.1693308804987	
L1 norm of params:	84047.435755125	
Loss: 	5.1142948954904	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.24540059347181	7.1299725786924	
L1 norm of params:	84051.275051334	
Loss: 	4.939054993518	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.24658753709199	7.0970503371053	
L1 norm of params:	84054.962252095	
Loss: 	4.8181958215276	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.24777448071217	7.0717133531286	
L1 norm of params:	84058.326959054	
Loss: 	4.7335706215167	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.2486646884273	7.0513361378483	
L1 norm of params:	84061.404782059	
Loss: 	4.672733251831	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.24955489614243	7.0354969832049	
L1 norm of params:	84064.181248959	
Loss: 	4.6284502451006	
