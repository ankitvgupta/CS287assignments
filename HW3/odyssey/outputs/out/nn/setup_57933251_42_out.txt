[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.022848664688427	3.9570573916193	
L1 norm of params:	833898.55975689	
Loss: 	9.2491329543083	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.036498516320475	3.9215040205738	
L1 norm of params:	833896.83492348	
Loss: 	9.2157503350454	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.057566765578635	3.8868425478337	
L1 norm of params:	833895.6375138	
Loss: 	9.182918781662	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.083679525222552	3.8514469717755	
L1 norm of params:	833895.02438158	
Loss: 	9.1490340246439	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.10059347181009	3.8142084863231	
L1 norm of params:	833894.84690711	
Loss: 	9.1126985024868	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.11988130563798	3.7744729488776	
L1 norm of params:	833895.07649094	
Loss: 	9.072413925265	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.1406528189911	3.7320609678491	
L1 norm of params:	833895.71427728	
Loss: 	9.0275344787119	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.15548961424332	3.6870409805774	
L1 norm of params:	833896.67810524	
Loss: 	8.9768837385811	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.17507418397626	3.6399981178787	
L1 norm of params:	833897.83801983	
Loss: 	8.9204829711817	
