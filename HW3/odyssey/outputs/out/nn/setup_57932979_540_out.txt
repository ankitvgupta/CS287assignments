[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.16795252225519	3.9559143348858	
L1 norm of params:	86026.611117189	
Loss: 	6.932919389837	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.33887240356083	6.1873306295477	
L1 norm of params:	96637.37876189	
Loss: 	4.1325570232234	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.3406528189911	6.216324932341	
L1 norm of params:	97791.545961157	
Loss: 	4.0625731843829	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.35845697329377	6.0903789217538	
L1 norm of params:	99544.972632823	
Loss: 	4.0518056456457	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.37537091988131	6.0034999533617	
L1 norm of params:	102675.31009041	
Loss: 	4.1048098615232	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.3486646884273	6.4054522040677	
L1 norm of params:	102677.85254886	
Loss: 	4.0756215332076	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.38338278931751	5.9190957167765	
L1 norm of params:	109936.57384026	
Loss: 	4.0283847328765	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.36439169139466	6.1780744618065	
L1 norm of params:	108907.65216913	
Loss: 	3.9911358624616	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.35103857566766	6.4207982687443	
L1 norm of params:	108759.15487976	
Loss: 	4.0815497412551	
