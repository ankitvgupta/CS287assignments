[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.013353115727003	3.9753347752422	
L1 norm of params:	849046.64534441	
Loss: 	9.2542225748325	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56231454005935	2.2814858184134	
L1 norm of params:	1774066.9308923	
Loss: 	12.395791649933	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.5593471810089	2.7752264149411	
L1 norm of params:	3420010.8714274	
Loss: 	17.8834732204	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.56587537091988	3.1097809567019	
L1 norm of params:	6333729.766356	
Loss: 	19.766681531683	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.5566765578635	3.1436889678636	
L1 norm of params:	10504669.213985	
Loss: 	20.076696350405	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.54629080118694	3.1537850922525	
L1 norm of params:	13739652.00841	
Loss: 	20.202431338457	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.54807121661721	3.1495908661992	
L1 norm of params:	17917253.188559	
Loss: 	20.761257501377	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.54035608308605	3.1612806562831	
L1 norm of params:	22976214.53231	
Loss: 	20.856049321584	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.52373887240356	3.1733417122073	
L1 norm of params:	30235368.795072	
Loss: 	21.093700251492	
