[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.014243323442136	3.9770308714624	
L1 norm of params:	834280.19706405	
Loss: 	9.238639879718	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.1620178041543	3.6615987450424	
L1 norm of params:	834276.74079005	
Loss: 	9.0110428173744	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.29169139465875	3.2757960985281	
L1 norm of params:	834290.40127564	
Loss: 	8.6207156986603	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.38427299703264	2.9203661649599	
L1 norm of params:	834298.44351627	
Loss: 	8.1680186926493	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.43976261127596	2.6442200445156	
L1 norm of params:	834304.85311311	
Loss: 	7.7871743403247	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.46884272997033	2.4935830414324	
L1 norm of params:	834310.25306492	
Loss: 	7.6137492602647	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.49020771513353	2.3910344807489	
L1 norm of params:	834319.09625372	
Loss: 	7.540481643926	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.5026706231454	2.3117463500072	
L1 norm of params:	834330.61417657	
Loss: 	7.4958263155069	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.5106824925816	2.2495416906062	
L1 norm of params:	834343.12027242	
Loss: 	7.4651763338184	
