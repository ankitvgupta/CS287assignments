[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.020178041543027	3.9608618375794	
L1 norm of params:	834523.06829841	
Loss: 	9.3110142857942	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.57181008902077	2.0599951909787	
L1 norm of params:	1320133.1917472	
Loss: 	7.4700049274706	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.5620178041543	2.0168463939365	
L1 norm of params:	1103731.2753529	
Loss: 	7.94869866085	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.56409495548961	2.5197863244448	
L1 norm of params:	1417518.6492593	
Loss: 	10.80973685887	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56557863501484	2.6670023059083	
L1 norm of params:	1583677.7876088	
Loss: 	11.263505758191	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.5646884272997	2.9399593700466	
L1 norm of params:	1814999.1701325	
Loss: 	12.109764746266	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56557863501484	3.2203598563862	
L1 norm of params:	2092965.6228203	
Loss: 	12.989150041415	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.56379821958457	3.4294423399819	
L1 norm of params:	2411784.9560073	
Loss: 	13.606767419784	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.56706231454006	3.545334931087	
L1 norm of params:	2868577.4940652	
Loss: 	13.948676566943	
