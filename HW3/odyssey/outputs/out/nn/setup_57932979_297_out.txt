[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	100	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.1919881305638	3.9310653004273	
L1 norm of params:	85880.304403344	
Loss: 	6.9010876846485	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.25816023738872	6.7009133890923	
L1 norm of params:	85913.620028271	
Loss: 	4.2883588107542	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.26854599406528	6.8100466132719	
L1 norm of params:	85931.766625982	
Loss: 	4.0985887864003	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.27121661721068	6.820625016856	
L1 norm of params:	85943.340920954	
Loss: 	3.9798311702947	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.27359050445104	6.8168320350589	
L1 norm of params:	85952.769932677	
Loss: 	3.9073628106517	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.27715133531157	6.8028322790614	
L1 norm of params:	85961.733257244	
Loss: 	3.8573382024982	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.27566765578635	6.7826581768997	
L1 norm of params:	85971.141565655	
Loss: 	3.8208918119698	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.27744807121662	6.7601773836528	
L1 norm of params:	85981.256283987	
Loss: 	3.792067814164	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.27744807121662	6.7370119296672	
L1 norm of params:	85992.107922614	
Loss: 	3.7689532277475	
