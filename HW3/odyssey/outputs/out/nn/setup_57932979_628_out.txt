[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.18635014836795	4.071968408577	
L1 norm of params:	25808.835632398	
Loss: 	6.7544752762755	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.29020771513353	6.8034157746364	
L1 norm of params:	53006.648774849	
Loss: 	3.8269311935434	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.28783382789318	7.8840787521784	
L1 norm of params:	67994.782797087	
Loss: 	4.4755362505346	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.29525222551929	8.3494605733954	
L1 norm of params:	105378.65413032	
Loss: 	4.856240736239	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.29792284866469	8.8823211496365	
L1 norm of params:	142571.28717196	
Loss: 	5.3293675607204	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.3053412462908	9.4397114318001	
L1 norm of params:	176282.15444993	
Loss: 	5.8190378565991	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.30593471810089	9.9464050660492	
L1 norm of params:	207656.8344718	
Loss: 	6.232503283538	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.30385756676558	10.280512838037	
L1 norm of params:	242516.68807723	
Loss: 	6.5286469614553	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.30385756676558	10.486484734187	
L1 norm of params:	283124.12905545	
Loss: 	6.6461037017422	
