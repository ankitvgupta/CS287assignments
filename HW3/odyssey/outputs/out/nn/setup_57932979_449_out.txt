[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	100	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.16824925816024	3.9929780898993	
L1 norm of params:	45820.320922379	
Loss: 	6.6360319839563	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.2673590504451	9.4228489208623	
L1 norm of params:	134585.51434876	
Loss: 	2.3225235482337	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.27655786350148	11.911623472314	
L1 norm of params:	239506.02336699	
Loss: 	3.0741191996508	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.27596439169139	12.615603209022	
L1 norm of params:	448926.90901578	
Loss: 	3.1232660376405	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.28516320474777	12.803123438116	
L1 norm of params:	663641.24928605	
Loss: 	3.0673109389264	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.28605341246291	12.920745729425	
L1 norm of params:	837804.50309876	
Loss: 	2.9904738142182	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.29139465875371	13.014003449246	
L1 norm of params:	990099.94797725	
Loss: 	3.1427097728542	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.28813056379822	13.074404390321	
L1 norm of params:	1142426.8599601	
Loss: 	3.7327870799976	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.28219584569733	13.134199202672	
L1 norm of params:	1300077.5767076	
Loss: 	3.4949530480932	
