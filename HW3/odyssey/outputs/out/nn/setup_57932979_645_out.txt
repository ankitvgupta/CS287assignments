[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.18486646884273	3.9856346119355	
L1 norm of params:	84048.336307645	
Loss: 	6.9229793661556	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.32314540059347	6.2591446482618	
L1 norm of params:	92963.596279022	
Loss: 	4.1860605851587	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.34896142433234	6.147081108392	
L1 norm of params:	94435.386140855	
Loss: 	4.1390490267581	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.34569732937685	6.1653006633217	
L1 norm of params:	95636.078763638	
Loss: 	4.081922164162	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.34747774480712	6.1468680952718	
L1 norm of params:	96828.568214677	
Loss: 	4.047887489938	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.36290801186944	6.0457844377431	
L1 norm of params:	98079.447594613	
Loss: 	4.0277052107248	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.35252225519288	6.145606799257	
L1 norm of params:	98989.70296483	
Loss: 	4.0007538859702	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.33768545994065	6.4651941348606	
L1 norm of params:	95835.505545838	
Loss: 	4.0951005244644	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.35192878338279	6.3344080235402	
L1 norm of params:	98774.71545164	
Loss: 	4.1701491715773	
