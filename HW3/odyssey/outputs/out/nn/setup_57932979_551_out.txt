[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.17596439169139	3.9508184860402	
L1 norm of params:	41730.406312565	
Loss: 	6.8549288201888	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.26379821958457	9.522087347008	
L1 norm of params:	76075.785970714	
Loss: 	2.2579261121626	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.26557863501484	12.070210262023	
L1 norm of params:	107917.13646144	
Loss: 	2.8289280982447	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.26795252225519	12.706136496117	
L1 norm of params:	168768.96536945	
Loss: 	3.1564215146826	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.26795252225519	12.920439096321	
L1 norm of params:	259724.24634023	
Loss: 	3.2248832247009	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.26854599406528	13.088213458533	
L1 norm of params:	323978.94867173	
Loss: 	3.1887302600147	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.26676557863501	13.151669316461	
L1 norm of params:	413696.5365202	
Loss: 	3.1815191025129	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.26439169139466	13.165457323367	
L1 norm of params:	536846.99407954	
Loss: 	3.1077732127482	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.2673590504451	13.243360220751	
L1 norm of params:	675354.9446858	
Loss: 	3.0312169210953	
