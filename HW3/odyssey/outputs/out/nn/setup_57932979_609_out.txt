[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	100	Lambda:	1	Minibatch size:	32	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.14747774480712	3.8834978764983	
L1 norm of params:	83890.358228165	
Loss: 	6.9662646323947	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.26765578635015	9.2889654851673	
L1 norm of params:	141358.96378906	
Loss: 	2.2826963170979	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.27744807121662	11.942928045242	
L1 norm of params:	216174.09667516	
Loss: 	3.0192996512402	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.27952522255193	12.611314285065	
L1 norm of params:	360227.95445549	
Loss: 	2.916391122982	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.28278931750742	12.822847732326	
L1 norm of params:	540600.08259345	
Loss: 	3.2690702873043	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.28249258160237	12.964346030974	
L1 norm of params:	673240.39370667	
Loss: 	3.4820171078252	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.28041543026706	13.071216085277	
L1 norm of params:	793088.60874722	
Loss: 	3.4056776089542	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.28486646884273	13.090467603381	
L1 norm of params:	898900.53246946	
Loss: 	4.4031080461216	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.28308605341246	13.150418045381	
L1 norm of params:	1047864.1988107	
Loss: 	3.4315040034464	
