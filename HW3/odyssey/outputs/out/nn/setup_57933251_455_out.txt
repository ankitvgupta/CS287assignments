[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.019881305637982	3.9808762867607	
L1 norm of params:	435735.914244	
Loss: 	9.282525706158	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.29525222551929	3.3710722195669	
L1 norm of params:	435742.72855166	
Loss: 	8.6907179665181	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.39762611275964	2.7953803351186	
L1 norm of params:	435774.13629809	
Loss: 	8.0229941197551	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.45074183976261	2.5799092479303	
L1 norm of params:	435790.20139222	
Loss: 	7.8454681443158	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.47655786350148	2.4377610165576	
L1 norm of params:	435801.54192712	
Loss: 	7.7364589964017	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.49584569732938	2.3380965853252	
L1 norm of params:	435811.1778588	
Loss: 	7.6642268284665	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.5053412462908	2.2658819080277	
L1 norm of params:	435818.58442506	
Loss: 	7.6173522745793	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.51305637982196	2.210580059293	
L1 norm of params:	435823.88989456	
Loss: 	7.5852731483556	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.52195845697329	2.1659770635052	
L1 norm of params:	435827.96181096	
Loss: 	7.561422887943	
