[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.025222551928783	3.9663752231024	
L1 norm of params:	235687.20670631	
Loss: 	9.335098630721	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.17804154302671	3.7017643881909	
L1 norm of params:	235683.0050634	
Loss: 	9.1272603836884	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.31572700296736	3.2426672185054	
L1 norm of params:	235696.66676779	
Loss: 	8.6469738652798	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.39910979228487	2.8351587495563	
L1 norm of params:	235712.26579524	
Loss: 	8.1629010626873	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.44391691394659	2.6091203429046	
L1 norm of params:	235720.88983315	
Loss: 	7.9097919315916	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.47240356083086	2.4723453462222	
L1 norm of params:	235728.27986444	
Loss: 	7.8030856973182	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.48902077151335	2.3723351630967	
L1 norm of params:	235737.8016001	
Loss: 	7.735868302154	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.50237388724036	2.2978371984048	
L1 norm of params:	235748.2993886	
Loss: 	7.6890107532235	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.50919881305638	2.2410774410227	
L1 norm of params:	235758.71525148	
Loss: 	7.6558433690586	
