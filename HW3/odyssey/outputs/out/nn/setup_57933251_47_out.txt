[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.022848664688427	3.9299844232335	
L1 norm of params:	416212.59734655	
Loss: 	9.1953005474542	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56824925816024	1.8276083206053	
L1 norm of params:	490295.41305726	
Loss: 	6.7147987925432	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.58100890207715	1.7636355038615	
L1 norm of params:	575111.96133271	
Loss: 	6.5868130509961	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.58456973293769	1.7453796848889	
L1 norm of params:	632416.58631233	
Loss: 	6.5518433189713	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.58160237388724	1.7453152160566	
L1 norm of params:	665617.54705862	
Loss: 	6.5420775301715	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.58545994065282	1.7398044139038	
L1 norm of params:	668873.2304415	
Loss: 	6.5310322782098	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.586646884273	1.7350639718062	
L1 norm of params:	657909.56350937	
Loss: 	6.5258624758776	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.58575667655786	1.7284802481544	
L1 norm of params:	630217.6641053	
Loss: 	6.513576573988	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.58456973293769	1.7308966696768	
L1 norm of params:	605332.19874856	
Loss: 	6.5172432777015	
