[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.001	Lambda:	1	Minibatch size:	128	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	50	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.015430267062315	3.9860800397366	
L1 norm of params:	834560.75885894	
Loss: 	9.2859952868929	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56884272997033	2.0575534896105	
L1 norm of params:	1430942.5313675	
Loss: 	7.5217790279828	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.57062314540059	2.0482584687159	
L1 norm of params:	1134358.2310609	
Loss: 	7.9917440923068	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.5700296735905	2.4710326522025	
L1 norm of params:	1369078.6934529	
Loss: 	10.135904147099	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.56617210682493	2.7038731207031	
L1 norm of params:	1804244.2048252	
Loss: 	11.546097181504	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.56379821958457	2.9133159535515	
L1 norm of params:	2346810.6645935	
Loss: 	12.154592536319	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.56409495548961	3.2077768717093	
L1 norm of params:	2522870.5851709	
Loss: 	12.969476139816	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.5646884272997	3.4256643085847	
L1 norm of params:	2578960.4718586	
Loss: 	13.578230670282	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.56498516320475	3.5467973919221	
L1 norm of params:	2744156.2942883	
Loss: 	13.981493753695	
