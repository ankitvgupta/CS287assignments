[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	25	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.14925816023739	4.0095329783652	
L1 norm of params:	23979.585666146	
Loss: 	6.9696827846966	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.24421364985163	5.3372427857798	
L1 norm of params:	23980.294136466	
Loss: 	6.1512302373787	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.2459940652819	6.9846731439183	
L1 norm of params:	23983.870995244	
Loss: 	5.4555233824792	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.24629080118694	7.1858235404519	
L1 norm of params:	23985.350871589	
Loss: 	5.2489781427636	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.24629080118694	7.1571849445276	
L1 norm of params:	23987.460822257	
Loss: 	5.0808126858009	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.24688427299703	7.1227597890703	
L1 norm of params:	23989.878175081	
Loss: 	4.9494089035868	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.24718100890208	7.0994577252371	
L1 norm of params:	23992.207259653	
Loss: 	4.8527594344705	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.24807121661721	7.0837928597668	
L1 norm of params:	23994.356273434	
Loss: 	4.7809389363481	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.24777448071217	7.0730651475224	
L1 norm of params:	23996.363974637	
Loss: 	4.7273529151552	
