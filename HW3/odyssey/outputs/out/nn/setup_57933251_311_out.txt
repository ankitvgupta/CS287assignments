[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_2.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	2	
Full valid size	 73760
     2
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.019287833827893	3.9489340836404	
L1 norm of params:	434863.72592215	
Loss: 	9.2616062798024	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.027299703264095	3.9124654170678	
L1 norm of params:	434862.13650002	
Loss: 	9.2242851742815	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.042433234421365	3.8759166466111	
L1 norm of params:	434860.92113815	
Loss: 	9.1866041531055	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.07893175074184	3.8376574034788	
L1 norm of params:	434860.16972117	
Loss: 	9.146639602394	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.11038575667656	3.7967981524953	
L1 norm of params:	434859.85667193	
Loss: 	9.1029440703296	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.13679525222552	3.7517968776838	
L1 norm of params:	434860.02932983	
Loss: 	9.053538737679	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.1700296735905	3.7014297817928	
L1 norm of params:	434860.59722542	
Loss: 	8.9966931505711	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.19821958456973	3.6456807277503	
L1 norm of params:	434861.65596239	
Loss: 	8.9312723136848	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.21899109792285	3.5844514977481	
L1 norm of params:	434863.08480839	
Loss: 	8.8562940021743	
