[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/SMALL_5.hdf5	Classifier:	nn	Alpha:	1	Eta:	0.01	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	50	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	1000	nfeatures:	1000	d_win:	5	
Full valid size	 73760
     5
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.18724035608309	4.0007642845764	
L1 norm of params:	43844.153722713	
Loss: 	6.9190061566965	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.24569732937685	5.7680434567975	
L1 norm of params:	43846.324784356	
Loss: 	5.956794311777	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.24658753709199	7.0528714100478	
L1 norm of params:	43850.713575841	
Loss: 	5.4217703037561	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.24658753709199	7.1184179554584	
L1 norm of params:	43853.604885182	
Loss: 	5.2161787953193	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.24629080118694	7.0957660326004	
L1 norm of params:	43856.878822794	
Loss: 	5.0561774884189	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.24688427299703	7.0774086739883	
L1 norm of params:	43860.017590879	
Loss: 	4.9390855715674	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.24777448071217	7.0656422746327	
L1 norm of params:	43862.843541364	
Loss: 	4.8521212336397	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.2486646884273	7.056137300757	
L1 norm of params:	43865.458058325	
Loss: 	4.7852319856556	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.24836795252226	7.0475685299556	
L1 norm of params:	43867.979710912	
Loss: 	4.7323239542497	
