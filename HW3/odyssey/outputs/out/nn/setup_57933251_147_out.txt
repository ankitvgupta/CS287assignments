[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	sgd	Hidden Layers:	10	Embedding size:	100	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.025519287833828	3.9947012614971	
L1 norm of params:	815903.69984371	
Loss: 	9.27520903471	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.031157270029674	3.9634305256506	
L1 norm of params:	815902.37100804	
Loss: 	9.24520362328	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.037685459940653	3.9341131291873	
L1 norm of params:	815901.26974234	
Loss: 	9.2167442026389	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.050445103857567	3.9066807732495	
L1 norm of params:	815900.39267305	
Loss: 	9.1894527507733	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.070326409495549	3.8805803887469	
L1 norm of params:	815899.66928794	
Loss: 	9.162446037932	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.083679525222552	3.854249398053	
L1 norm of params:	815899.11729008	
Loss: 	9.1347141725648	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.09673590504451	3.8267756028085	
L1 norm of params:	815898.74863925	
Loss: 	9.1055883595865	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.11424332344214	3.7980739484502	
L1 norm of params:	815898.51016968	
Loss: 	9.074765198946	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.12433234421365	3.7691570285389	
L1 norm of params:	815898.38469742	
Loss: 	9.0430023608436	
