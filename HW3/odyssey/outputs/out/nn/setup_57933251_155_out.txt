[?1034hDatafile:	/n/home09/ankitgupta/CS287/CS287assignments/HW3/PTB_1.hdf5	Classifier:	nn	Alpha:	1	Eta:	1	Lambda:	1	Minibatch size:	1024	Num Epochs:	20	Optimizer:	adagrad	Hidden Layers:	10	Embedding size:	50	K:	10	
Sample dist	1	10001	
nclasses:	10001	nfeatures:	10001	d_win:	1	
Full valid size	 73760
     1
[torch.LongStorage of size 2]

 73760
[torch.LongStorage of size 1]

Making neural network model	
Got params and grads	
Starting predictions	
Initialized output predictions tensor	
Starting Validation accuracy	0.018100890207715	3.9568132661205	
L1 norm of params:	416889.79404012	
Loss: 	9.2560439382817	
Starting predictions	
Initialized output predictions tensor	
Epoch 1 Validation accuracy:	0.56706231454006	1.8432803652499	
L1 norm of params:	491304.45111291	
Loss: 	6.7342631843878	
Starting predictions	
Initialized output predictions tensor	
Epoch 2 Validation accuracy:	0.57804154302671	1.7665554200075	
L1 norm of params:	573608.61950317	
Loss: 	6.5949410854056	
Starting predictions	
Initialized output predictions tensor	
Epoch 3 Validation accuracy:	0.58189910979228	1.7511911996361	
L1 norm of params:	626837.76533688	
Loss: 	6.5499288501086	
Starting predictions	
Initialized output predictions tensor	
Epoch 4 Validation accuracy:	0.58338278931751	1.7399838290141	
L1 norm of params:	656406.62061474	
Loss: 	6.534701061739	
Starting predictions	
Initialized output predictions tensor	
Epoch 5 Validation accuracy:	0.58456973293769	1.737310933199	
L1 norm of params:	654408.50464146	
Loss: 	6.5226208100491	
Starting predictions	
Initialized output predictions tensor	
Epoch 6 Validation accuracy:	0.58160237388724	1.7273421333884	
L1 norm of params:	638621.57627401	
Loss: 	6.5067241672101	
Starting predictions	
Initialized output predictions tensor	
Epoch 7 Validation accuracy:	0.58219584569733	1.7287198310182	
L1 norm of params:	617149.261252	
Loss: 	6.5028434881583	
Starting predictions	
Initialized output predictions tensor	
Epoch 8 Validation accuracy:	0.58278931750742	1.7240204786147	
L1 norm of params:	600129.68474889	
Loss: 	6.4769945025114	
